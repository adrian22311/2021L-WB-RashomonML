{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praca domowa 4\n",
    "Odtworzenie modeli z artykułu [Predictive modeling in urgent care: a comparative study of machine learning approaches](https://academic.oup.com/jamiaopen/article/1/1/87/5032901) .\n",
    "\n",
    "Link do repozytorium tego artykułu: [https://github.com/illidanlab/urgent-care-comparative](https://github.com/illidanlab/urgent-care-comparative) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcje pomocnicze\n",
    "Poniższe funkcje zostały wzięte z repozytorium powyższego artykułu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc as auc_score, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import *\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_subsample(x,y,subsample_size=1.0):\n",
    "    class_xs = []\n",
    "    min_elems = None\n",
    "    for yi in np.unique(y):\n",
    "        elems = x[(y == yi)]\n",
    "        class_xs.append((yi, elems))\n",
    "        if min_elems == None or elems.shape[0] < min_elems:\n",
    "            min_elems = elems.shape[0]\n",
    "    use_elems = min_elems\n",
    "    if subsample_size < 1:\n",
    "        use_elems = int(min_elems*subsample_size)\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for ci,this_xs in class_xs:\n",
    "        if len(this_xs) > use_elems:\n",
    "            np.random.shuffle(this_xs)\n",
    "\n",
    "        x_ = this_xs[:use_elems]\n",
    "        y_ = np.empty(use_elems)\n",
    "        y_.fill(ci)\n",
    "\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "\n",
    "    xs = np.concatenate(xs)\n",
    "    ys = np.concatenate(ys)\n",
    "\n",
    "    return xs,ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_score(y_te, yhat):\n",
    "    fpr, tpr, thresholds = roc_curve(y_te, yhat)\n",
    "    roc_auc = auc_score(fpr, tpr)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    yhat[yhat>=optimal_threshold]=1; yhat[yhat<optimal_threshold]=0\n",
    "    yhat=[int(i) for i in yhat]\n",
    "    #matrix = confusion_matrix(y_te, yhat)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_te, yhat).ravel()\n",
    "    sen=1.0* (tp/(tp+fn))\n",
    "    spec=1.0* (tn/(tn+fp))\n",
    "    f1=f1_score(y_te,yhat)\n",
    "    return roc_auc, f1, sen, spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function was simplified a bit\n",
    "def get_task():\n",
    "    # returns target for in-hospital mortality\n",
    "    with open(\"y\", \"rb\") as f:\n",
    "        labels = pickle.load(f)\n",
    "    \n",
    "    temp = [yy[0] for yy in labels]\n",
    "    \n",
    "    return np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(X, y, model_type):\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    data = {}\n",
    "    count = 0\n",
    "\n",
    "    X,y= np.array(X), np.array(y)\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        count +=1\n",
    "        \n",
    "        X_tr, X_te = X[train_index], X[test_index]\n",
    "        y_tr, y_te = y[train_index], y[test_index]\n",
    "        \n",
    "        if len(X_tr.shape) >2:\n",
    "            input_shape = (X_tr.shape[1], X_tr.shape[-1])\n",
    "        else:\n",
    "            input_shape = (X_tr.shape[-1],)\n",
    "            \n",
    "        if model_type == \"mlp\":\n",
    "            model = mlp_model(input_shape) \n",
    "        elif model_type == \"rfc\":\n",
    "            model = RF(n_estimators = 450, verbose = 1, n_jobs = -1)\n",
    "        elif model_type == \"gbc\":\n",
    "            model = GBC(n_estimators = 400, learning_rate = 0.09, verbose = 1)\n",
    "        else:\n",
    "            model = None\n",
    "        \n",
    "        #train over epochs\n",
    "        for e in range(100):\n",
    "            \n",
    "            if model_type != \"mlp\":\n",
    "                break\n",
    "                \n",
    "            #subsample\n",
    "            xs, ys = balanced_subsample(X_tr, y_tr, 1.0)\n",
    "            ys = np.array([[i] for i in ys])\n",
    "\n",
    "            model.fit(x = xs, y=ys, \n",
    "                      batch_size = 32,\n",
    "                      validation_split=.2, \n",
    "                      epochs=1, \n",
    "                      verbose=0)\n",
    "            \n",
    "        if model_type != \"mlp\":\n",
    "            xs, ys = balanced_subsample(X_tr, y_tr, 1)\n",
    "            model.fit(xs, ys)\n",
    "\n",
    "        yhat = model.predict(X_tr)\n",
    "        tr_auc, _, _, _ = single_score(y_tr, yhat)\n",
    "    \n",
    "        yhat2 = model.predict(X_te)\n",
    "        te_auc, f1_score, sen, spec = single_score(y_te, yhat2)\n",
    "            \n",
    "        data[count] = {'tr_auc': tr_auc, 'f1_score':f1_score, 'te_auc': te_auc, 'sen':sen, 'spec': spec}\n",
    "    \n",
    "    return model, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane po preprocessingu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Zmienna `X` została stworzona na podstawie cech, będących szeregami czasowymi. Każda taka cecha przerobiona została na min, średnią, max oraz odchylenie standardowe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.22535211e-02, 0.00000000e+00, 5.43478261e-02, ...,\n",
       "        4.03017024e-01, 1.33952979e-01, 4.75067826e-01],\n",
       "       [2.58215962e-01, 1.18421053e-01, 3.26086957e-01, ...,\n",
       "        4.10958588e-14, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.11267606e-01, 4.05553814e-01, 8.69565217e-02, ...,\n",
       "        2.52207581e-01, 1.88907108e-01, 2.31845699e-01],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        4.10958588e-14, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 2.10526316e-01, 0.00000000e+00, ...,\n",
       "        2.64952543e-01, 2.88610525e-01, 4.89848547e-02],\n",
       "       [3.20522201e-01, 1.57894737e-01, 0.00000000e+00, ...,\n",
       "        4.83805376e-02, 3.83338758e-02, 1.06946021e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load(\"X48.npy\")\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Zmienna `y` jest wektorem 0-1. 0 oznacza, iż dany pacjent przeżył, 1, że nie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = get_task()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Odtworzenie modeli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej reprodukowane będą modele klasyczne do zadania `in-hospital mortality`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "\n",
    "res = [] # to save results from model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_shape, hidden = 256, targets = 1, multiclass = False, learn_rate = 1e-4):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden, activation = 'relu', input_shape = input_shape))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(hidden, activation = 'relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(hidden, activation = 'relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(targets))\n",
    "    if multiclass:\n",
    "        model.add(Activation('softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=learn_rate, beta_1 =.5 ), \n",
    "                      metrics=['categorical_accuracy'])\n",
    "    else:\n",
    "        model.add(Activation('sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(lr=learn_rate, beta_1 =.5 ), metrics=['accuracy'])\n",
    "    return (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, data = pipeline(X, y, \"mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.append(pd.DataFrame(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfc, data_rfc = pipeline(X, y, \"rfc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.append(pd.DataFrame(data_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gbc, data_gbc = pipeline(X, y, \"gbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.append(pd.DataFrame(data_gbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wnioski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mlp_av</th>\n",
       "      <th>mlp_std</th>\n",
       "      <th>rfc_av</th>\n",
       "      <th>rfc_std</th>\n",
       "      <th>gbc_av</th>\n",
       "      <th>gbc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tr_auc</th>\n",
       "      <td>0.873796</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.883403</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.848945</td>\n",
       "      <td>0.003959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.429742</td>\n",
       "      <td>0.016478</td>\n",
       "      <td>0.424311</td>\n",
       "      <td>0.012273</td>\n",
       "      <td>0.448952</td>\n",
       "      <td>0.016758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>te_auc</th>\n",
       "      <td>0.848446</td>\n",
       "      <td>0.008341</td>\n",
       "      <td>0.767847</td>\n",
       "      <td>0.011077</td>\n",
       "      <td>0.775384</td>\n",
       "      <td>0.017240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sen</th>\n",
       "      <td>0.809055</td>\n",
       "      <td>0.020538</td>\n",
       "      <td>0.806024</td>\n",
       "      <td>0.033422</td>\n",
       "      <td>0.781135</td>\n",
       "      <td>0.048300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spec</th>\n",
       "      <td>0.734357</td>\n",
       "      <td>0.024202</td>\n",
       "      <td>0.729670</td>\n",
       "      <td>0.023380</td>\n",
       "      <td>0.769634</td>\n",
       "      <td>0.025135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mlp_av   mlp_std    rfc_av   rfc_std    gbc_av   gbc_std\n",
       "tr_auc    0.873796  0.003013  0.883403  0.002567  0.848945  0.003959\n",
       "f1_score  0.429742  0.016478  0.424311  0.012273  0.448952  0.016758\n",
       "te_auc    0.848446  0.008341  0.767847  0.011077  0.775384  0.017240\n",
       "sen       0.809055  0.020538  0.806024  0.033422  0.781135  0.048300\n",
       "spec      0.734357  0.024202  0.729670  0.023380  0.769634  0.025135"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"mlp_av\", \"mlp_std\", \"rfc_av\", \"rfc_std\", \"gbc_av\", \"gbc_std\"]\n",
    "results = None\n",
    "\n",
    "for i in range(len(res)):\n",
    "    results = pd.concat([results, res[i].mean(axis=1)], axis=1)\n",
    "    results = pd.concat([results, res[i].std(axis=1)], axis=1)\n",
    "\n",
    "results.columns = columns\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki uzyskane przez autorów artykułu są w **Table 1**.\n",
    "<img src=\"results.png\" width=\"500\" />\n",
    "\n",
    "### MLP\n",
    "Zreprodukowane MLP dało podobny jak w artykule AUC, a reszta metryk(mimo że była w miarę bliska) była gorsza. Wynika to najprawdopodobniej z tego, że autorzy nie podali wszystkich parametrów swojego najlepszego modelu MLP(przy tej próbie odtworzenia użyte zostały domyślne).\n",
    "### Random forest\n",
    "Tutaj wszystkie wyniki były gorsze od tych z artykułu. Przyczyna jak wyżej.\n",
    "### Gradient boosting\n",
    "Jedyny model, który powtórzył wyniki autorów artykułu. Warto jednak zaznaczyć, że jego odpowiednik z artykułu miał najsłabsze wyniki(w naszym przypadku najgorzej wypadł `random forest`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

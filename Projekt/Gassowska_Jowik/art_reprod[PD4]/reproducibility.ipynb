{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import psycopg2\n",
    "import sys\n",
    "import datetime as dt\n",
    "import mp_utils as mp\n",
    "\n",
    "# to display dataframes in notebooks\n",
    "# from IPython.display import display, HTML\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# used to print out pretty pandas dataframes\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# used to impute mean for data and standardize for computational stability\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression is our favourite model ever\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV # l2 regularized regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# used to calculate AUROC/accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "# gradient boosting - must download package https://github.com/dmlc/xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "#import matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib.font_manager import FontProperties # for unicode fonts\n",
    "#%matplotlib inline\n",
    "\n",
    "# below config used on pc70\n",
    "#sqluser = 'alistairewj'\n",
    "#dbname = 'mimic'\n",
    "#schema_name = 'mimiciii'\n",
    "#query_schema = 'SET search_path to public,' + schema_name + ';'\n",
    "\n",
    "\n",
    "# two options for loading data\n",
    "# option 1) use SQL - requires database and to have run queries/make_all.sql\n",
    "# option 2) use CSVs downloaded\n",
    "USE_SQL=0\n",
    "USE_CSV=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6386894, 55)\n"
     ]
    }
   ],
   "source": [
    "if USE_SQL:\n",
    "    # Connect to local postgres version of mimic\n",
    "    con = psycopg2.connect(dbname=dbname, user=sqluser)\n",
    "\n",
    "    # exclusion criteria:\n",
    "    #   - less than 15 years old\n",
    "    #   - stayed in the ICU less than 4 hours\n",
    "    #   - never have any chartevents data (i.e. likely administrative error)\n",
    "    #   - organ donor accounts (administrative \"readmissions\" for patients who died in hospital)\n",
    "    query = query_schema + \\\n",
    "    \"\"\"\n",
    "    select \n",
    "        *\n",
    "    from dm_cohort\n",
    "    \"\"\"\n",
    "    co = pd.read_sql_query(query,con)\n",
    "    \n",
    "    # convert the inclusion flags to boolean\n",
    "    for c in co.columns:\n",
    "        if c[0:10]=='inclusion_':\n",
    "            co[c] = co[c].astype(bool)\n",
    "\n",
    "    # extract static vars into a separate dataframe\n",
    "    df_static = pd.read_sql_query(query_schema + 'select * from mp_static_data', con)\n",
    "    #for dtvar in ['intime','outtime','deathtime']:\n",
    "    #    df_static[dtvar] = pd.to_datetime(df_static[dtvar])\n",
    "\n",
    "    vars_static = [u'is_male', u'emergency_admission', u'age',\n",
    "                   # services\n",
    "                   u'service_any_noncard_surg',\n",
    "                   u'service_any_card_surg',\n",
    "                   u'service_cmed',\n",
    "                   u'service_traum',\n",
    "                   u'service_nmed',\n",
    "                   # ethnicities\n",
    "                   u'race_black',u'race_hispanic',u'race_asian',u'race_other',\n",
    "                   # phatness\n",
    "                   u'height', u'weight', u'bmi']\n",
    "\n",
    "\n",
    "    # get ~5 million rows containing data from errbody\n",
    "    # this takes a little bit of time to load into memory (~2 minutes)\n",
    "\n",
    "    # %%time results\n",
    "    # CPU times: user 42.8 s, sys: 1min 3s, total: 1min 46s\n",
    "    # Wall time: 2min 7s\n",
    "\n",
    "    df = pd.read_sql_query(query_schema + 'select * from mp_data', con)\n",
    "    df.drop('subject_id',axis=1,inplace=True)\n",
    "    df.drop('hadm_id',axis=1,inplace=True)\n",
    "    df.sort_values(['icustay_id','hr'],axis=0,ascending=True,inplace=True)\n",
    "\n",
    "    # get death information\n",
    "    df_death = pd.read_sql_query(query_schema + \"\"\"\n",
    "    select \n",
    "    co.subject_id, co.hadm_id, co.icustay_id\n",
    "    , ceil(extract(epoch from (co.outtime - co.intime))/60.0/60.0) as dischtime_hours\n",
    "    , ceil(extract(epoch from (adm.deathtime - co.intime))/60.0/60.0) as deathtime_hours\n",
    "    , case when adm.deathtime is null then 0 else 1 end as death\n",
    "    from dm_cohort co\n",
    "    inner join admissions adm\n",
    "    on co.hadm_id = adm.hadm_id\n",
    "    where co.excluded = 0\n",
    "    \"\"\", con)\n",
    "    \n",
    "    # get censoring information\n",
    "    df_censor = pd.read_sql_query(query_schema + \"\"\"\n",
    "    select co.icustay_id, min(cs.charttime) as censortime\n",
    "    , ceil(extract(epoch from min(cs.charttime-co.intime) )/60.0/60.0) as censortime_hours\n",
    "    from dm_cohort co \n",
    "    inner join mp_code_status cs\n",
    "    on co.icustay_id = cs.icustay_id\n",
    "    where cmo+dnr+dni+dncpr+cmo_notes>0\n",
    "    and co.excluded = 0\n",
    "    group by co.icustay_id\n",
    "    \"\"\", con)\n",
    "    \n",
    "    # extract static vars into a separate dataframe\n",
    "    df_static = pd.read_sql_query(query_schema + 'select * from mp_static_data', con)\n",
    "    \n",
    "elif USE_CSV:\n",
    "    co = pd.read_csv('.\\data\\data_compressed\\df_cohort.csv')\n",
    "    \n",
    "    # convert the inclusion flags to boolean\n",
    "    for c in co.columns:\n",
    "        if c[0:10]=='inclusion_':\n",
    "            co[c] = co[c].astype(bool)\n",
    "    df = pd.read_csv('.\\data\\data_compressed\\df_data.csv')\n",
    "    df_static = pd.read_csv('.\\data\\data_compressed\\df_static_data.csv')\n",
    "    df_censor = pd.read_csv('.\\data\\data_compressed\\df_censor.csv')\n",
    "    df_death = pd.read_csv('.\\data\\data_compressed\\df_death.csv')\n",
    "    \n",
    "else:\n",
    "    print('Must use SQL or CSV to load data!')\n",
    "    \n",
    "    \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[0], axis=1)\n",
    "co = co.drop(co.columns[0], axis=1)\n",
    "df_static = df_static.drop(df_static.columns[0], axis=1)\n",
    "df_censor = df_censor.drop(df_censor.columns[0], axis=1)\n",
    "df_death = df_death.drop(df_death.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base exclusion criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort - initial size: 52085 ICU stays\n",
      "      0 (0.00%) - exclusion_over_15\n",
      "      0 (0.00%) - exclusion_valid_data\n",
      "      0 (0.00%) - exclusion_stay_lt_4hr\n",
      "      0 (0.00%) - exclusion_organ_donor\n",
      "      0 (0.00%) - all exclusions\n",
      "\n",
      "Final cohort size: 52085 ICU stays (100.00%).\n"
     ]
    }
   ],
   "source": [
    "# print out the exclusions *SEQUENTIALLY* - i.e. if already excluded, don't re-print\n",
    "print('Cohort - initial size: {} ICU stays'.format(co.shape[0]))\n",
    "\n",
    "idxRem = np.zeros(co.shape[0],dtype=bool)\n",
    "for c in co.columns:\n",
    "    if c[0:len('exclusion_')]=='exclusion_':\n",
    "        N_REM = np.sum( (co[c].values==1) )\n",
    "        print('  {:5g} ({:2.2f}%) - {}'.format(N_REM,N_REM*100.0/co.shape[0], c))\n",
    "        idxRem[co[c].values==1] = True\n",
    "\n",
    "# summarize all exclusions\n",
    "N_REM = np.sum(idxRem)\n",
    "print('  {:5g} ({:2.2f}%) - {}'.format(N_REM,N_REM*100.0/co.shape[0], 'all exclusions'))\n",
    "print('')\n",
    "print('Final cohort size: {} ICU stays ({:2.2f}%).'.format(co.shape[0] - np.sum(idxRem), (1-np.mean(idxRem))*100.0))\n",
    "co = co.loc[~idxRem,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mortality stats\n",
    "\n",
    "### Mortality in base cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "death_48hr_post_icu_admit                1614 of 52085 died (3.10%).\n",
      "death_icu                                4185 of 52085 died (8.03%).\n",
      "death_in_hospital                        6192 of 52085 died (11.89%).\n",
      "death_30dy_post_icu_admit                7567 of 52085 died (14.53%).\n",
      "death_30dy_post_icu_disch                8081 of 52085 died (15.52%).\n",
      "death_30dy_post_hos_disch                8633 of 52085 died (16.57%).\n",
      "death_6mo_post_hos_disch                12788 of 52085 died (24.55%).\n",
      "death_1yr_post_hos_disch                15052 of 52085 died (28.90%).\n",
      "death_2yr_post_hos_disch                17758 of 52085 died (34.09%).\n",
      "death_30dy_post_hos_admit                7124 of 52085 died (13.68%).\n"
     ]
    }
   ],
   "source": [
    "# mortality stats for base cohort\n",
    "for c in co.columns:\n",
    "    if c[0:len('death_')]=='death_':\n",
    "        N_ALL = co.shape[0]\n",
    "        N = co.set_index('icustay_id').loc[:,c].sum()\n",
    "        print('{:40s}{:5g} of {:5g} died ({:2.2f}%).'.format(c, N, N_ALL, N*100.0/N_ALL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mortality in MIMIC-II patients staying >= 24 hours\n",
    "\n",
    "This is mainly an example of how the `inclFcn` works. It derives from the cohort a boolean index of patients to retain in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "death_48hr_post_icu_admit                 405 of 23497 died (1.72%).\n",
      "death_icu                                2020 of 23497 died (8.60%).\n",
      "death_in_hospital                        3034 of 23497 died (12.91%).\n",
      "death_30dy_post_icu_admit                3613 of 23497 died (15.38%).\n",
      "death_30dy_post_icu_disch                3933 of 23497 died (16.74%).\n",
      "death_30dy_post_hos_disch                4212 of 23497 died (17.93%).\n",
      "death_6mo_post_hos_disch                 6205 of 23497 died (26.41%).\n",
      "death_1yr_post_hos_disch                 7362 of 23497 died (31.33%).\n",
      "death_2yr_post_hos_disch                 8879 of 23497 died (37.79%).\n",
      "death_30dy_post_hos_admit                3390 of 23497 died (14.43%).\n"
     ]
    }
   ],
   "source": [
    "inclFcn = lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_stay_ge_24hr'],'icustay_id']\n",
    "\n",
    "# mortality stats for base cohort\n",
    "for c in co.columns:\n",
    "    if c[0:len('death_')]=='death_':\n",
    "        N_ALL = inclFcn(co).shape[0]\n",
    "        N = co.set_index('icustay_id').loc[inclFcn(co),c].sum()\n",
    "        print('{:40s}{:5g} of {:5g} died ({:2.2f}%).'.format(c, N, N_ALL, N*100.0/N_ALL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the same function in a slightly more obscure way - with the benefit of being able to list all inclusions in a list. This just helps readability in the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "death_48hr_post_icu_admit                 405 of 23497 died (1.72%).\n",
      "death_icu                                2020 of 23497 died (8.60%).\n",
      "death_in_hospital                        3034 of 23497 died (12.91%).\n",
      "death_30dy_post_icu_admit                3613 of 23497 died (15.38%).\n",
      "death_30dy_post_icu_disch                3933 of 23497 died (16.74%).\n",
      "death_30dy_post_hos_disch                4212 of 23497 died (17.93%).\n",
      "death_6mo_post_hos_disch                 6205 of 23497 died (26.41%).\n",
      "death_1yr_post_hos_disch                 7362 of 23497 died (31.33%).\n",
      "death_2yr_post_hos_disch                 8879 of 23497 died (37.79%).\n",
      "death_30dy_post_hos_admit                3390 of 23497 died (14.43%).\n"
     ]
    }
   ],
   "source": [
    "inclusions = ['inclusion_only_mimicii', 'inclusion_stay_ge_24hr']\n",
    "inclFcn = lambda x: x.loc[x[inclusions].all(axis=1),'icustay_id']\n",
    "\n",
    "# mortality stats for base cohort\n",
    "for c in co.columns:\n",
    "    if c[0:len('death_')]=='death_':\n",
    "        N_ALL = inclFcn(co).shape[0]\n",
    "        N = co.set_index('icustay_id').loc[inclFcn(co),c].sum()\n",
    "        print('{:40s}{:5g} of {:5g} died ({:2.2f}%).'.format(c, N, N_ALL, N*100.0/N_ALL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclusion criteria\n",
    "\n",
    "Each study has its own exclusion criteria (sometimes studies have multiple experiments). We define a dictionary of all exclusions with the dictionary key as the study name. Some studies have multiple experiments, so we append *a*, *b*, or *c*.\n",
    "\n",
    "The dictionary stores a length 2 list. The first element defines the window for data extraction: it contains a dictionary of the windows and the corresponding window sizes. The second element is the exclusion criteria. Both are functions which use `co` or `df` as their input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we can define the different windows: there aren't that many!\n",
    "df_tmp=co.copy().set_index('icustay_id')\n",
    "\n",
    "# admission+12 hours\n",
    "time_12hr = df_tmp.copy()\n",
    "time_12hr['windowtime'] = 12\n",
    "time_12hr = time_12hr['windowtime'].to_dict()\n",
    "\n",
    "# admission+24 hours\n",
    "time_24hr = df_tmp.copy()\n",
    "time_24hr['windowtime'] = 24\n",
    "time_24hr = time_24hr['windowtime'].to_dict()\n",
    "\n",
    "# admission+48 hours\n",
    "time_48hr = df_tmp.copy()\n",
    "time_48hr['windowtime'] = 48\n",
    "time_48hr = time_48hr['windowtime'].to_dict()\n",
    "\n",
    "# admission+72 hours\n",
    "time_72hr = df_tmp.copy()\n",
    "time_72hr['windowtime'] = 72\n",
    "time_72hr = time_72hr['windowtime'].to_dict()\n",
    "\n",
    "# admission+96 hours\n",
    "time_96hr = df_tmp.copy()\n",
    "time_96hr['windowtime'] = 96\n",
    "time_96hr = time_96hr['windowtime'].to_dict()\n",
    "\n",
    "# entire stay\n",
    "time_all = df_tmp.copy()\n",
    "time_all = time_all['dischtime_hours'].apply(np.ceil).astype(int).to_dict()\n",
    "\n",
    "# 12 hours before the patient died/discharged\n",
    "time_predeath = df_tmp.copy()\n",
    "time_predeath['windowtime'] = time_predeath['dischtime_hours']\n",
    "idx = time_predeath['deathtime_hours']<time_predeath['dischtime_hours']\n",
    "time_predeath.loc[idx,'windowtime'] = time_predeath.loc[idx,'deathtime_hours']\n",
    "# move from discharge/death time to 12 hours beforehand\n",
    "time_predeath['windowtime'] = time_predeath['windowtime']-12\n",
    "time_predeath = time_predeath['windowtime'].apply(np.ceil).astype(int).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example params used to extract patient data\n",
    "# element 1: dictionary specifying end time of window for each patient\n",
    "# element 2: size of window\n",
    "# element 3: extra hours added to make it easier to get data on labs (and allows us to get labs pre-ICU)\n",
    "# e.g. [time_24hr, 8, 24] is\n",
    "#   (1) window ends at admission+24hr\n",
    "#   (2) window is 8 hours long\n",
    "#   (3) lab window is 8+24=32 hours long\n",
    "\n",
    "def inclFcn(x, inclusions):\n",
    "    return x.loc[x[inclusions].all(axis=1),'icustay_id']\n",
    "\n",
    "\n",
    "# this one is used more than once, so we define it here\n",
    "hugExclFcnMIMIC3 = lambda x: x.loc[x['inclusion_over_18']&x['inclusion_hug2009_obs']&x['inclusion_hug2009_not_nsicu_csicu']&x['inclusion_first_admission']&x['inclusion_full_code']&x['inclusion_not_brain_death']&x['inclusion_not_crf'],'icustay_id'].values\n",
    "hugExclFcn = lambda x: np.intersect1d(hugExclFcnMIMIC3(x),x.loc[x['inclusion_only_mimicii'],'icustay_id'].values)\n",
    "\n",
    "\n",
    "# physionet2012 subset - not exact but close\n",
    "def physChallExclFcn(x):\n",
    "    out = x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_stay_ge_48hr']&x['inclusion_has_saps'],'icustay_id'].values\n",
    "    out = np.sort(out)\n",
    "    out = out[0:4000]\n",
    "    return out\n",
    " \n",
    "# caballero2015 is a random subsample - then limits to 18yrs, resulting in 11648\n",
    "def caballeroExclFcn(x):\n",
    "    out = x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18'],'icustay_id'].values\n",
    "    out = np.sort(out)\n",
    "    out = out[0:11648]\n",
    "    return out\n",
    "\n",
    "np.random.seed(546345)\n",
    "W_extra = 24\n",
    "\n",
    "exclusions = OrderedDict([\n",
    "['caballero2015dynamically_a',  [[time_24hr, 24, W_extra], caballeroExclFcn, 'hospital_expire_flag']],\n",
    "['caballero2015dynamically_b',  [[time_48hr, 48, W_extra], caballeroExclFcn, 'hospital_expire_flag']],\n",
    "['caballero2015dynamically_c',  [[time_72hr, 72, W_extra], caballeroExclFcn, 'hospital_expire_flag']],\n",
    "['calvert2016computational',    [[time_predeath, 5, W_extra], lambda x: x.loc[x['inclusion_over_18']&x['inclusion_only_micu']&x['inclusion_calvert2016_obs']&x['inclusion_stay_ge_17hr']&x['inclusion_stay_le_500hr']&x['inclusion_non_alc_icd9'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['calvert2016using',            [[time_predeath, 5, W_extra], lambda x: x.loc[x['inclusion_over_18']&x['inclusion_only_micu']&x['inclusion_calvert2016_obs']&x['inclusion_stay_ge_17hr']&x['inclusion_stay_le_500hr'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['celi2012database_a',          [[time_72hr, 72, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_aki_icd9'],'icustay_id'].values , 'hospital_expire_flag']],\n",
    "['celi2012database_b',          [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_sah_icd9'],'icustay_id'].values , 'hospital_expire_flag']],\n",
    "['che2016recurrent_a',          [[time_48hr, 48, W_extra], lambda x: x.loc[x['inclusion_over_18'],'icustay_id'].values , 'death_48hr_post_icu_admit']],\n",
    "['che2016recurrent_b',          [[time_48hr, 48, W_extra], physChallExclFcn , 'hospital_expire_flag']],\n",
    "['ding2016mortality',           [[time_48hr, 48, W_extra], physChallExclFcn , 'hospital_expire_flag']],\n",
    "['ghassemi2014unfolding_a',     [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_ge_100_non_stop_words']&x['inclusion_stay_ge_24hr'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['ghassemi2014unfolding_b',     [[time_12hr, 12, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_ge_100_non_stop_words']&x['inclusion_stay_ge_12hr'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['ghassemi2014unfolding_c',     [[time_12hr, 12, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_ge_100_non_stop_words']&x['inclusion_stay_ge_12hr'],'icustay_id'].values, 'death_30dy_post_hos_disch']],\n",
    "['ghassemi2014unfolding_d',     [[time_12hr, 12, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_ge_100_non_stop_words']&x['inclusion_stay_ge_12hr'],'icustay_id'].values, 'death_1yr_post_hos_disch']],\n",
    "['ghassemi2015multivariate_a',    [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_ge_100_non_stop_words']&x['inclusion_gt_6_notes']&x['inclusion_stay_ge_24hr']&x['inclusion_has_saps'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['ghassemi2015multivariate_b',    [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_ge_100_non_stop_words']&x['inclusion_gt_6_notes']&x['inclusion_stay_ge_24hr']&x['inclusion_has_saps'],'icustay_id'].values, 'death_1yr_post_hos_disch']],\n",
    "['grnarova2016neural_a',          [[time_all,  24, W_extra], lambda x: x.loc[x['inclusion_over_18']&x['inclusion_multiple_hadm'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['grnarova2016neural_b',          [[time_all,  24, W_extra], lambda x: x.loc[x['inclusion_over_18']&x['inclusion_multiple_hadm'],'icustay_id'].values, 'death_30dy_post_hos_disch']],\n",
    "['grnarova2016neural_c',          [[time_all,  24, W_extra], lambda x: x.loc[x['inclusion_over_18']&x['inclusion_multiple_hadm'],'icustay_id'].values, 'death_1yr_post_hos_disch']],\n",
    "['harutyunyan2017multitask',    [[time_48hr, 48, W_extra], lambda x: x.loc[x['inclusion_over_18']&x['inclusion_multiple_icustay'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['hoogendoorn2016prediction',   [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_hug2009_obs']&x['inclusion_stay_ge_24hr'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['hug2009icu',                  [[time_24hr, 24, W_extra], hugExclFcn, 'death_30dy_post_icu_disch']],\n",
    "['johnson2012patient',          [[time_48hr, 48, W_extra], physChallExclFcn, 'hospital_expire_flag']],\n",
    "['johnson2014data',             [[time_48hr, 48, W_extra], physChallExclFcn, 'hospital_expire_flag']],\n",
    "['joshi2012prognostic',         [[time_24hr, 24, W_extra], hugExclFcn, 'hospital_expire_flag']],\n",
    "['joshi2016identifiable',       [[time_48hr, 48, W_extra], lambda x: x.loc[x['inclusion_over_18']&x['inclusion_stay_ge_48hr'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['lee2015customization_a',        [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_lee2015_service']&x['inclusion_has_saps']&x['inclusion_stay_ge_24hr'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['lee2015customization_b',        [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_lee2015_service']&x['inclusion_has_saps']&x['inclusion_stay_ge_24hr'],'icustay_id'].values, 'death_30dy_post_hos_disch']],\n",
    "['lee2015customization_c',        [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_lee2015_service']&x['inclusion_has_saps']&x['inclusion_stay_ge_24hr'],'icustay_id'].values, 'death_2yr_post_hos_disch']],\n",
    "['lee2015personalized',         [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_has_saps']&x['inclusion_stay_ge_24hr'],'icustay_id'].values, 'death_30dy_post_hos_disch']],\n",
    "['lee2017patient',              [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_has_saps']&x['inclusion_stay_ge_24hr'],'icustay_id'].values, 'death_30dy_post_hos_disch']],\n",
    "['lehman2012risk',              [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_has_saps']&x['inclusion_stay_ge_24hr']&x['inclusion_first_admission'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['luo2016interpretable_a',        [[time_all,  24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_has_sapsii']&x['inclusion_no_disch_summary'],'icustay_id'].values, 'death_30dy_post_hos_disch']],\n",
    "['luo2016interpretable_b',        [[time_all,  24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_has_sapsii']&x['inclusion_no_disch_summary'],'icustay_id'].values, 'death_6mo_post_hos_disch']],\n",
    "['luo2016predicting',           [[time_24hr, 12, W_extra], lambda x: np.intersect1d(hugExclFcn(x),x.loc[x['inclusion_stay_ge_24hr'],'icustay_id'].values) , 'death_30dy_post_icu_disch']],\n",
    "['pirracchio2015mortality',     [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii'],'icustay_id'].values , 'hospital_expire_flag']],\n",
    "['ripoll2014sepsis',            [[time_24hr, 24, W_extra], lambda x: x.loc[x['inclusion_only_mimicii']&x['inclusion_over_18']&x['inclusion_has_saps']&x['inclusion_not_explicit_sepsis'],'icustay_id'].values, 'hospital_expire_flag']],\n",
    "['wojtusiak2017c',              [[time_all,  24, W_extra], lambda x: x.loc[x['inclusion_over_65']&x['inclusion_alive_hos_disch'],'icustay_id'].values, 'death_30dy_post_hos_disch']]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare sample sizes and mortality rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11648 (22.36%) - Mortality = 13.01% - caballero2015dynamically_a\n",
      "11648 (22.36%) - Mortality = 13.01% - caballero2015dynamically_b\n",
      "11648 (22.36%) - Mortality = 13.01% - caballero2015dynamically_c\n",
      " 1985 ( 3.81%) - Mortality = 13.80% - calvert2016computational\n",
      "18396 (35.32%) - Mortality = 14.71% - calvert2016using\n",
      " 4741 ( 9.10%) - Mortality = 23.92% - celi2012database_a\n",
      " 1070 ( 2.05%) - Mortality = 19.16% - celi2012database_b\n",
      "51986 (99.81%) - Mortality =  3.10% - che2016recurrent_a\n",
      " 4000 ( 7.68%) - Mortality = 14.35% - che2016recurrent_b\n",
      " 4000 ( 7.68%) - Mortality = 14.35% - ding2016mortality\n",
      "23442 (45.01%) - Mortality = 12.92% - ghassemi2014unfolding_a\n",
      "28169 (54.08%) - Mortality = 12.20% - ghassemi2014unfolding_b\n",
      "28169 (54.08%) - Mortality = 16.92% - ghassemi2014unfolding_c\n",
      "28169 (54.08%) - Mortality = 29.76% - ghassemi2014unfolding_d\n",
      "21969 (42.18%) - Mortality = 13.51% - ghassemi2015multivariate_a\n",
      "21969 (42.18%) - Mortality = 32.35% - ghassemi2015multivariate_b\n",
      "29572 (56.78%) - Mortality = 12.49% - grnarova2016neural_a\n",
      "29572 (56.78%) - Mortality = 16.36% - grnarova2016neural_b\n",
      "29572 (56.78%) - Mortality = 24.63% - grnarova2016neural_c\n",
      "45493 (87.34%) - Mortality = 10.54% - harutyunyan2017multitask\n",
      "17545 (33.69%) - Mortality = 14.97% - hoogendoorn2016prediction\n",
      "10696 (20.54%) - Mortality =  6.35% - hug2009icu\n",
      " 4000 ( 7.68%) - Mortality = 14.35% - johnson2012patient\n",
      " 4000 ( 7.68%) - Mortality = 14.35% - johnson2014data\n",
      "10696 (20.54%) - Mortality =  4.14% - joshi2012prognostic\n",
      "26508 (50.89%) - Mortality = 14.95% - joshi2016identifiable\n",
      "20961 (40.24%) - Mortality = 12.69% - lee2015customization_a\n",
      "20961 (40.24%) - Mortality = 17.86% - lee2015customization_b\n",
      "20961 (40.24%) - Mortality = 38.07% - lee2015customization_c\n",
      "23443 (45.01%) - Mortality = 17.94% - lee2015personalized\n",
      "23443 (45.01%) - Mortality = 17.94% - lee2017patient\n",
      "21738 (41.74%) - Mortality = 12.32% - lehman2012risk\n",
      "27747 (53.27%) - Mortality = 17.05% - luo2016interpretable_a\n",
      "27747 (53.27%) - Mortality = 25.17% - luo2016interpretable_b\n",
      " 8931 (17.15%) - Mortality =  6.45% - luo2016predicting\n",
      "28795 (55.28%) - Mortality = 12.72% - pirracchio2015mortality\n",
      " 2251 ( 4.32%) - Mortality = 39.63% - ripoll2014sepsis\n",
      "22699 (43.58%) - Mortality =  7.74% - wojtusiak2017c\n"
     ]
    }
   ],
   "source": [
    "repro_stats = pd.DataFrame(None, columns=['N_Repro','Y_Repro'])\n",
    "\n",
    "N = co.shape[0]\n",
    "    \n",
    "for current_study in exclusions:\n",
    "    params, iid_keep, y_outcome_label = exclusions[current_study]\n",
    "    \n",
    "    # iid_keep is currently a function - apply it to co to get ICUSTAY_IDs to keep for this study\n",
    "    iid_keep = iid_keep(co)\n",
    "    \n",
    "    N_STUDY = iid_keep.shape[0]\n",
    "    Y_STUDY = co.set_index('icustay_id').loc[iid_keep,y_outcome_label].mean()*100.0\n",
    "    \n",
    "    # print size of cohort in study\n",
    "    print('{:5g} ({:5.2f}%) - Mortality = {:5.2f}% - {}'.format(\n",
    "            N_STUDY, N_STUDY*100.0/N, Y_STUDY,\n",
    "            current_study)\n",
    "         )\n",
    "    \n",
    "    repro_stats.loc[current_study] = [N_STUDY, Y_STUDY]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above dataframe, `repro_stats`, we can compare our results to those extracted manually from the studies. We load in the manual extraction from the `data` subfolder, merge it with this dataframe, and output to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_Study</th>\n",
       "      <th>N_Repro</th>\n",
       "      <th>Y_Study</th>\n",
       "      <th>Y_Repro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohort</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>caballero2015dynamically_a</th>\n",
       "      <td>11648</td>\n",
       "      <td>11648.0</td>\n",
       "      <td>-</td>\n",
       "      <td>13.006525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caballero2015dynamically_b</th>\n",
       "      <td>11648</td>\n",
       "      <td>11648.0</td>\n",
       "      <td>-</td>\n",
       "      <td>13.006525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caballero2015dynamically_c</th>\n",
       "      <td>11648</td>\n",
       "      <td>11648.0</td>\n",
       "      <td>-</td>\n",
       "      <td>13.006525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calvert2016computational</th>\n",
       "      <td>3054</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>12.84</td>\n",
       "      <td>13.803526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calvert2016using</th>\n",
       "      <td>9683</td>\n",
       "      <td>18396.0</td>\n",
       "      <td>10.68</td>\n",
       "      <td>14.709720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celi2012database_a</th>\n",
       "      <td>1400</td>\n",
       "      <td>4741.0</td>\n",
       "      <td>30.7</td>\n",
       "      <td>23.919004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celi2012database_b</th>\n",
       "      <td>223</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>19.158879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>che2016recurrent_a</th>\n",
       "      <td>4000</td>\n",
       "      <td>51986.0</td>\n",
       "      <td>13.85</td>\n",
       "      <td>3.095064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ding2016mortality</th>\n",
       "      <td>4000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>13.85</td>\n",
       "      <td>14.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghassemi2014unfolding_a</th>\n",
       "      <td>19308</td>\n",
       "      <td>23442.0</td>\n",
       "      <td>10.84</td>\n",
       "      <td>12.916987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghassemi2014unfolding_b</th>\n",
       "      <td>19308</td>\n",
       "      <td>28169.0</td>\n",
       "      <td>10.80</td>\n",
       "      <td>12.201356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghassemi2015multivariate_a</th>\n",
       "      <td>10202</td>\n",
       "      <td>21969.0</td>\n",
       "      <td>-</td>\n",
       "      <td>13.514498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grnarova2016neural_a</th>\n",
       "      <td>31244</td>\n",
       "      <td>29572.0</td>\n",
       "      <td>13.82</td>\n",
       "      <td>12.494928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harutyunyan2017multitask</th>\n",
       "      <td>42276</td>\n",
       "      <td>45493.0</td>\n",
       "      <td>-</td>\n",
       "      <td>10.535687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoogendoorn2016prediction</th>\n",
       "      <td>13923</td>\n",
       "      <td>17545.0</td>\n",
       "      <td>-</td>\n",
       "      <td>14.967227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>johnson2012patient</th>\n",
       "      <td>4000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>14.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>johnson2014data</th>\n",
       "      <td>4000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>14.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joshi2012prognostic</th>\n",
       "      <td>10066</td>\n",
       "      <td>10696.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.141735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lee2015customization_a</th>\n",
       "      <td>17490</td>\n",
       "      <td>20961.0</td>\n",
       "      <td>17.73</td>\n",
       "      <td>12.690234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lehman2012risk</th>\n",
       "      <td>14739</td>\n",
       "      <td>21738.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.319441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pirracchio2015mortality</th>\n",
       "      <td>24508</td>\n",
       "      <td>28795.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>12.720958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ripoll2014sepsis</th>\n",
       "      <td>2002</td>\n",
       "      <td>2251.0</td>\n",
       "      <td>21.10</td>\n",
       "      <td>39.626833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>che2016recurrent_b</th>\n",
       "      <td>19714</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>14.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hug2009icu</th>\n",
       "      <td>10066</td>\n",
       "      <td>10696.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.348168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>luo2016predicting</th>\n",
       "      <td>7863</td>\n",
       "      <td>8931.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.449446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joshi2016identifiable</th>\n",
       "      <td>17000</td>\n",
       "      <td>26508.0</td>\n",
       "      <td>-</td>\n",
       "      <td>14.950204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghassemi2014unfolding_c</th>\n",
       "      <td>19308</td>\n",
       "      <td>28169.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>16.919308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grnarova2016neural_b</th>\n",
       "      <td>31244</td>\n",
       "      <td>29572.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>16.363452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lee2015personalized</th>\n",
       "      <td>17490</td>\n",
       "      <td>23443.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>17.941390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lee2015customization_b</th>\n",
       "      <td>17490</td>\n",
       "      <td>20961.0</td>\n",
       "      <td>23.56</td>\n",
       "      <td>17.861743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lee2017patient</th>\n",
       "      <td>17152</td>\n",
       "      <td>23443.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>17.941390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>luo2016interpretable_a</th>\n",
       "      <td>18412</td>\n",
       "      <td>27747.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>17.054096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wojtusiak2017c</th>\n",
       "      <td>21651</td>\n",
       "      <td>22699.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.736024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>luo2016interpretable_b</th>\n",
       "      <td>18412</td>\n",
       "      <td>27747.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>25.166685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghassemi2014unfolding_d</th>\n",
       "      <td>19308</td>\n",
       "      <td>28169.0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>29.756115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghassemi2015multivariate_b</th>\n",
       "      <td>10202</td>\n",
       "      <td>21969.0</td>\n",
       "      <td>-</td>\n",
       "      <td>32.354682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grnarova2016neural_c</th>\n",
       "      <td>31244</td>\n",
       "      <td>29572.0</td>\n",
       "      <td>12.06</td>\n",
       "      <td>24.628027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lee2015customization_c</th>\n",
       "      <td>17152</td>\n",
       "      <td>20961.0</td>\n",
       "      <td>43.82</td>\n",
       "      <td>38.070703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            N_Study  N_Repro Y_Study    Y_Repro\n",
       "Cohort                                                         \n",
       "caballero2015dynamically_a    11648  11648.0       -  13.006525\n",
       "caballero2015dynamically_b    11648  11648.0       -  13.006525\n",
       "caballero2015dynamically_c    11648  11648.0       -  13.006525\n",
       "calvert2016computational       3054   1985.0   12.84  13.803526\n",
       "calvert2016using               9683  18396.0   10.68  14.709720\n",
       "celi2012database_a             1400   4741.0    30.7  23.919004\n",
       "celi2012database_b              223   1070.0    25.6  19.158879\n",
       "che2016recurrent_a             4000  51986.0   13.85   3.095064\n",
       "ding2016mortality              4000   4000.0   13.85  14.350000\n",
       "ghassemi2014unfolding_a       19308  23442.0   10.84  12.916987\n",
       "ghassemi2014unfolding_b       19308  28169.0   10.80  12.201356\n",
       "ghassemi2015multivariate_a    10202  21969.0       -  13.514498\n",
       "grnarova2016neural_a          31244  29572.0   13.82  12.494928\n",
       "harutyunyan2017multitask      42276  45493.0       -  10.535687\n",
       "hoogendoorn2016prediction     13923  17545.0       -  14.967227\n",
       "johnson2012patient             4000   4000.0       -  14.350000\n",
       "johnson2014data                4000   4000.0       -  14.350000\n",
       "joshi2012prognostic           10066  10696.0    12.0   4.141735\n",
       "lee2015customization_a        17490  20961.0   17.73  12.690234\n",
       "lehman2012risk                14739  21738.0    14.6  12.319441\n",
       "pirracchio2015mortality       24508  28795.0    12.2  12.720958\n",
       "ripoll2014sepsis               2002   2251.0   21.10  39.626833\n",
       "che2016recurrent_b            19714   4000.0     8.7  14.350000\n",
       "hug2009icu                    10066  10696.0    17.0   6.348168\n",
       "luo2016predicting              7863   8931.0    17.0   6.449446\n",
       "joshi2016identifiable         17000  26508.0       -  14.950204\n",
       "ghassemi2014unfolding_c       19308  28169.0    3.23  16.919308\n",
       "grnarova2016neural_b          31244  29572.0    3.70  16.363452\n",
       "lee2015personalized           17490  23443.0    15.1  17.941390\n",
       "lee2015customization_b        17490  20961.0   23.56  17.861743\n",
       "lee2017patient                17152  23443.0    15.1  17.941390\n",
       "luo2016interpretable_a        18412  27747.0     3.4  17.054096\n",
       "wojtusiak2017c                21651  22699.0     NaN   7.736024\n",
       "luo2016interpretable_b        18412  27747.0     9.5  25.166685\n",
       "ghassemi2014unfolding_d       19308  28169.0    3.34  29.756115\n",
       "ghassemi2015multivariate_b    10202  21969.0       -  32.354682\n",
       "grnarova2016neural_c          31244  29572.0   12.06  24.628027\n",
       "lee2015customization_c        17152  20961.0  43.82   38.070703"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_data = pd.read_csv('./data/study_data.csv')\n",
    "study_data.set_index('Cohort',inplace=True)\n",
    "# add in reproduction sample size // outcome\n",
    "study_data_merged = study_data.merge(repro_stats, how='left',\n",
    "                left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "# print out the table as it was in the paper (maybe a bit more precision)\n",
    "study_data_merged[ ['N_Study','N_Repro','Y_Study','Y_Repro'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define K-folds for AUROC comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define var_static which is used later\n",
    "#TODO: should refactor so this isn't needed\n",
    "var_min, var_max, var_first, var_last, var_sum, var_first_early, var_last_early, var_static = mp.vars_of_interest()\n",
    "\n",
    "K=5\n",
    "np.random.seed(871)\n",
    "# get unique subject_id (this is needed later)\n",
    "sid = np.sort(np.unique(df_death['subject_id'].values))\n",
    "\n",
    "# assign k-fold\n",
    "idxK_sid = np.random.permutation(sid.shape[0])\n",
    "idxK_sid = np.mod(idxK_sid,K)\n",
    "\n",
    "# get indices which map subject_ids in sid to the X dataframe\n",
    "idxMap = np.searchsorted(sid, df_death['subject_id'].values)\n",
    "\n",
    "# use these indices to map the k-fold integers\n",
    "idxK = idxK_sid[idxMap]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run results for a single study\n",
    "\n",
    "The below code cell:\n",
    "\n",
    "* extracts the cohort for a specific study\n",
    "* extracts the outcome of that study\n",
    "* builds predictive models in 5-fold cross-validation for that outcome\n",
    "\n",
    "The two models at the moment are Gradient Boosting (xgboost) and logistic regression (scikit-learn).\n",
    "This code cell only runs for one study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "========== BEGINNING celi2012database_b===========\n",
      "==================================================\n",
      "Reducing sample size from 52050 to 1070 (2.06%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:27:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:27:35.111426 - Finished fold 1 of 5. AUROC 0.905.\n",
      "[14:27:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:27:36.631151 - Finished fold 2 of 5. AUROC 0.964.\n",
      "[14:27:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:27:38.087684 - Finished fold 3 of 5. AUROC 0.899.\n",
      "[14:27:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:27:39.495161 - Finished fold 4 of 5. AUROC 0.887.\n",
      "[14:27:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:27:40.975378 - Finished fold 5 of 5. AUROC 0.858.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:27:41.107021 - Finished fold 1 of 5. AUROC 0.870.\n",
      "2021-04-13 14:27:41.191346 - Finished fold 2 of 5. AUROC 0.921.\n",
      "2021-04-13 14:27:41.291119 - Finished fold 3 of 5. AUROC 0.868.\n",
      "2021-04-13 14:27:41.402315 - Finished fold 4 of 5. AUROC 0.886.\n",
      "2021-04-13 14:27:41.505054 - Finished fold 5 of 5. AUROC 0.845.\n"
     ]
    }
   ],
   "source": [
    "# pick the study to run the example on\n",
    "current_study = 'celi2012database_b'\n",
    "    \n",
    "# Rough timing info:\n",
    "#     rf - 3 seconds per fold\n",
    "#    xgb - 30 seconds per fold\n",
    "# logreg - 4 seconds per fold\n",
    "#  lasso - 8 seconds per fold\n",
    "models = OrderedDict([\n",
    "          ['xgb', xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)],\n",
    "          #['lasso', LassoCV(cv=5,fit_intercept=True,normalize=True,max_iter=10000)],\n",
    "          #['rf', RandomForestClassifier()],\n",
    "          ['logreg', LogisticRegression(fit_intercept=True)]\n",
    "         ])\n",
    "\n",
    "print('')\n",
    "print('====================={}==========='.format('='*len(current_study)))\n",
    "print('========== BEGINNING {}==========='.format(current_study))\n",
    "print('====================={}==========='.format('='*len(current_study)))\n",
    "\n",
    "params = exclusions[current_study][0]\n",
    "df_data = mp.get_design_matrix(df, params[0], W=params[1], W_extra=params[2])\n",
    "\n",
    "# get a list of icustay_id who stayed at least 12 hours\n",
    "iid_keep = exclusions[current_study][1](co)\n",
    "print('Reducing sample size from {} to {} ({:2.2f}%).'.format(\n",
    "        df_data.shape[0], iid_keep.shape[0], iid_keep.shape[0]*100.0 / df_data.shape[0]))\n",
    "df_data = df_data.reindex(index = iid_keep)\n",
    "print('')\n",
    "\n",
    "y_outcome_label = exclusions[current_study][2]\n",
    "\n",
    "# load the data into a numpy array\n",
    "\n",
    "# first, the data from static vars from df_static\n",
    "X = df_data.merge(df_static.set_index('icustay_id')[var_static], how='left', left_index=True, right_index=True)\n",
    "# next, add in the outcome: death in hospital\n",
    "X = X.merge(co.set_index('icustay_id')[[y_outcome_label]], left_index=True, right_index=True)\n",
    "\n",
    "# map above K-fold indices to this dataset\n",
    "X = X.merge(co.set_index('icustay_id')[['subject_id']], left_index=True, right_index=True)\n",
    "# get indices which map subject_ids in sid to the X dataframe\n",
    "idxMap = np.searchsorted(sid, X['subject_id'].values)\n",
    "# use these indices to map the k-fold integers\n",
    "idxK = idxK_sid[idxMap]\n",
    "# drop the subject_id column\n",
    "X.drop('subject_id',axis=1,inplace=True)\n",
    "\n",
    "# convert to numpy data (assumes target, death, is the last column)\n",
    "X = X.values\n",
    "y = X[:,-1]\n",
    "X = X[:,0:-1]\n",
    "X_header = [x for x in df_data.columns.values] + var_static\n",
    "\n",
    "mdl_val = dict()\n",
    "results_val = dict()\n",
    "pred_val = dict()\n",
    "tar_val = dict()\n",
    "\n",
    "for mdl in models:\n",
    "    print('=============== {} ==============='.format(mdl))\n",
    "    mdl_val[mdl] = list()\n",
    "    results_val[mdl] = list() # initialize list for scores\n",
    "    pred_val[mdl] = list()\n",
    "    tar_val[mdl] = list()\n",
    "\n",
    "    if mdl == 'xgb':\n",
    "        # no pre-processing of data necessary for xgb\n",
    "        estimator = Pipeline([(mdl, models[mdl])])\n",
    "\n",
    "    else:\n",
    "        estimator = Pipeline([(\"imputer\", SimpleImputer(missing_values=np.nan,\n",
    "                                          strategy=\"mean\")),\n",
    "                      (\"scaler\", StandardScaler()),\n",
    "                      (mdl, models[mdl])]) \n",
    "\n",
    "    for k in range(K):\n",
    "        # train the model using all but the kth fold\n",
    "        curr_mdl = estimator.fit(X[idxK != k, :],y[idxK != k])\n",
    "\n",
    "        # get prediction on this dataset\n",
    "        if mdl == 'lasso':\n",
    "            curr_prob = curr_mdl.predict(X[idxK == k, :])\n",
    "        else:\n",
    "            curr_prob = curr_mdl.predict_proba(X[idxK == k, :])\n",
    "            curr_prob = curr_prob[:,1]\n",
    "\n",
    "        pred_val[mdl].append(curr_prob)\n",
    "        tar_val[mdl].append(y[idxK == k])\n",
    "\n",
    "        # calculate score (AUROC)\n",
    "        curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "\n",
    "        # add score to list of scores\n",
    "        results_val[mdl].append(curr_score)\n",
    "\n",
    "        # save the current model\n",
    "        mdl_val[mdl].append(curr_mdl)\n",
    "\n",
    "        print('{} - Finished fold {} of {}. AUROC {:0.3f}.'.format(dt.datetime.now(), k+1, K, curr_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run results for all results\n",
    "\n",
    "The below code block is identical to the above code block, except it loops over all studies evaluated. This code block takes a while - it is training ~150 models of each type. The final AUROCs are output to the `results.txt` file. The final models/results/predictions/targets are saved in various dictionaries with the suffix `_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== ========================== ==========\n",
      "========== BEGINNING caballero2015dynamically_a ==========\n",
      "==================== ========================== ==========\n",
      "Reducing sample size from 52050 to 11648 (22.38%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:30:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:30:18.298676 - Finished fold 1 of 5. AUROC 0.896.\n",
      "[14:30:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:30:26.415379 - Finished fold 2 of 5. AUROC 0.897.\n",
      "[14:30:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:30:33.893557 - Finished fold 3 of 5. AUROC 0.912.\n",
      "[14:30:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:30:41.450978 - Finished fold 4 of 5. AUROC 0.910.\n",
      "[14:30:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:30:48.719429 - Finished fold 5 of 5. AUROC 0.915.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:30:49.357442 - Finished fold 1 of 5. AUROC 0.885.\n",
      "2021-04-13 14:30:49.902703 - Finished fold 2 of 5. AUROC 0.887.\n",
      "2021-04-13 14:30:50.453647 - Finished fold 3 of 5. AUROC 0.880.\n",
      "2021-04-13 14:30:51.004196 - Finished fold 4 of 5. AUROC 0.894.\n",
      "2021-04-13 14:30:51.527146 - Finished fold 5 of 5. AUROC 0.901.\n",
      "\n",
      "==================== ========================== ==========\n",
      "========== BEGINNING caballero2015dynamically_b ==========\n",
      "==================== ========================== ==========\n",
      "Reducing sample size from 52050 to 11648 (22.38%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:31:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:31:15.352539 - Finished fold 1 of 5. AUROC 0.916.\n",
      "[14:31:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:31:22.581182 - Finished fold 2 of 5. AUROC 0.914.\n",
      "[14:31:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:31:30.401039 - Finished fold 3 of 5. AUROC 0.927.\n",
      "[14:31:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:31:38.373824 - Finished fold 4 of 5. AUROC 0.925.\n",
      "[14:31:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:31:46.672970 - Finished fold 5 of 5. AUROC 0.927.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:31:47.210492 - Finished fold 1 of 5. AUROC 0.894.\n",
      "2021-04-13 14:31:47.712040 - Finished fold 2 of 5. AUROC 0.908.\n",
      "2021-04-13 14:31:48.243827 - Finished fold 3 of 5. AUROC 0.903.\n",
      "2021-04-13 14:31:48.752761 - Finished fold 4 of 5. AUROC 0.913.\n",
      "2021-04-13 14:31:49.222730 - Finished fold 5 of 5. AUROC 0.911.\n",
      "\n",
      "==================== ========================== ==========\n",
      "========== BEGINNING caballero2015dynamically_c ==========\n",
      "==================== ========================== ==========\n",
      "Reducing sample size from 52050 to 11648 (22.38%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:32:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:32:17.038567 - Finished fold 1 of 5. AUROC 0.922.\n",
      "[14:32:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:32:25.350794 - Finished fold 2 of 5. AUROC 0.926.\n",
      "[14:32:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:32:33.465001 - Finished fold 3 of 5. AUROC 0.938.\n",
      "[14:32:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:32:41.854021 - Finished fold 4 of 5. AUROC 0.936.\n",
      "[14:32:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:32:50.054190 - Finished fold 5 of 5. AUROC 0.935.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:32:50.709519 - Finished fold 1 of 5. AUROC 0.904.\n",
      "2021-04-13 14:32:51.220014 - Finished fold 2 of 5. AUROC 0.919.\n",
      "2021-04-13 14:32:51.691679 - Finished fold 3 of 5. AUROC 0.913.\n",
      "2021-04-13 14:32:52.183722 - Finished fold 4 of 5. AUROC 0.925.\n",
      "2021-04-13 14:32:52.707049 - Finished fold 5 of 5. AUROC 0.924.\n",
      "\n",
      "==================== ======================== ==========\n",
      "========== BEGINNING calvert2016computational ==========\n",
      "==================== ======================== ==========\n",
      "Reducing sample size from 52042 to 1985 (3.81%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:33:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:33:03.948297 - Finished fold 1 of 5. AUROC 0.958.\n",
      "[14:33:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 14:33:05.741675 - Finished fold 2 of 5. AUROC 0.974.\n",
      "[14:33:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:33:07.531263 - Finished fold 3 of 5. AUROC 0.947.\n",
      "[14:33:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:33:09.385060 - Finished fold 4 of 5. AUROC 0.934.\n",
      "[14:33:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:33:11.129404 - Finished fold 5 of 5. AUROC 0.976.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:33:11.289527 - Finished fold 1 of 5. AUROC 0.902.\n",
      "2021-04-13 14:33:11.445064 - Finished fold 2 of 5. AUROC 0.959.\n",
      "2021-04-13 14:33:11.594654 - Finished fold 3 of 5. AUROC 0.940.\n",
      "2021-04-13 14:33:11.788241 - Finished fold 4 of 5. AUROC 0.887.\n",
      "2021-04-13 14:33:11.981968 - Finished fold 5 of 5. AUROC 0.950.\n",
      "\n",
      "==================== ================ ==========\n",
      "========== BEGINNING calvert2016using ==========\n",
      "==================== ================ ==========\n",
      "Reducing sample size from 52042 to 18396 (35.35%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:33:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:33:28.797555 - Finished fold 1 of 5. AUROC 0.925.\n",
      "[14:33:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:33:37.647490 - Finished fold 2 of 5. AUROC 0.941.\n",
      "[14:33:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:33:46.946340 - Finished fold 3 of 5. AUROC 0.933.\n",
      "[14:33:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:33:56.214988 - Finished fold 4 of 5. AUROC 0.936.\n",
      "[14:33:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:34:05.954224 - Finished fold 5 of 5. AUROC 0.932.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:34:06.667489 - Finished fold 1 of 5. AUROC 0.901.\n",
      "2021-04-13 14:34:07.433272 - Finished fold 2 of 5. AUROC 0.927.\n",
      "2021-04-13 14:34:08.174501 - Finished fold 3 of 5. AUROC 0.918.\n",
      "2021-04-13 14:34:08.915208 - Finished fold 4 of 5. AUROC 0.911.\n",
      "2021-04-13 14:34:09.676316 - Finished fold 5 of 5. AUROC 0.911.\n",
      "\n",
      "==================== ================== ==========\n",
      "========== BEGINNING celi2012database_a ==========\n",
      "==================== ================== ==========\n",
      "Reducing sample size from 52050 to 4741 (9.11%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:34:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:34:32.001114 - Finished fold 1 of 5. AUROC 0.866.\n",
      "[14:34:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:34:36.220960 - Finished fold 2 of 5. AUROC 0.882.\n",
      "[14:34:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:34:40.311712 - Finished fold 3 of 5. AUROC 0.878.\n",
      "[14:34:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:34:44.262907 - Finished fold 4 of 5. AUROC 0.894.\n",
      "[14:34:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:34:48.432651 - Finished fold 5 of 5. AUROC 0.891.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:34:48.787042 - Finished fold 1 of 5. AUROC 0.853.\n",
      "2021-04-13 14:34:49.051653 - Finished fold 2 of 5. AUROC 0.878.\n",
      "2021-04-13 14:34:49.309774 - Finished fold 3 of 5. AUROC 0.880.\n",
      "2021-04-13 14:34:49.521754 - Finished fold 4 of 5. AUROC 0.884.\n",
      "2021-04-13 14:34:49.759084 - Finished fold 5 of 5. AUROC 0.893.\n",
      "\n",
      "==================== ================== ==========\n",
      "========== BEGINNING celi2012database_b ==========\n",
      "==================== ================== ==========\n",
      "Reducing sample size from 52050 to 1070 (2.06%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:35:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:35:02.642347 - Finished fold 1 of 5. AUROC 0.905.\n",
      "[14:35:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:35:04.096205 - Finished fold 2 of 5. AUROC 0.964.\n",
      "[14:35:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:35:05.583854 - Finished fold 3 of 5. AUROC 0.899.\n",
      "[14:35:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:35:07.111282 - Finished fold 4 of 5. AUROC 0.887.\n",
      "[14:35:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 14:35:08.706570 - Finished fold 5 of 5. AUROC 0.858.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:35:08.830331 - Finished fold 1 of 5. AUROC 0.870.\n",
      "2021-04-13 14:35:08.926652 - Finished fold 2 of 5. AUROC 0.921.\n",
      "2021-04-13 14:35:09.021795 - Finished fold 3 of 5. AUROC 0.868.\n",
      "2021-04-13 14:35:09.146690 - Finished fold 4 of 5. AUROC 0.886.\n",
      "2021-04-13 14:35:09.249136 - Finished fold 5 of 5. AUROC 0.845.\n",
      "\n",
      "==================== ================== ==========\n",
      "========== BEGINNING che2016recurrent_a ==========\n",
      "==================== ================== ==========\n",
      "Reducing sample size from 52050 to 51986 (99.88%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:35:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:35:54.728799 - Finished fold 1 of 5. AUROC 0.988.\n",
      "[14:35:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:36:25.613908 - Finished fold 2 of 5. AUROC 0.989.\n",
      "[14:36:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:36:55.422743 - Finished fold 3 of 5. AUROC 0.984.\n",
      "[14:36:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:37:26.309458 - Finished fold 4 of 5. AUROC 0.983.\n",
      "[14:37:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:37:56.632258 - Finished fold 5 of 5. AUROC 0.986.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:37:58.497261 - Finished fold 1 of 5. AUROC 0.969.\n",
      "2021-04-13 14:38:00.296672 - Finished fold 2 of 5. AUROC 0.967.\n",
      "2021-04-13 14:38:02.092000 - Finished fold 3 of 5. AUROC 0.965.\n",
      "2021-04-13 14:38:03.902921 - Finished fold 4 of 5. AUROC 0.969.\n",
      "2021-04-13 14:38:05.695841 - Finished fold 5 of 5. AUROC 0.961.\n",
      "\n",
      "==================== ================== ==========\n",
      "========== BEGINNING che2016recurrent_b ==========\n",
      "==================== ================== ==========\n",
      "Reducing sample size from 52050 to 4000 (7.68%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:38:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:38:23.263017 - Finished fold 1 of 5. AUROC 0.824.\n",
      "[14:38:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:38:25.970253 - Finished fold 2 of 5. AUROC 0.826.\n",
      "[14:38:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:38:28.962233 - Finished fold 3 of 5. AUROC 0.861.\n",
      "[14:38:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:38:31.881593 - Finished fold 4 of 5. AUROC 0.853.\n",
      "[14:38:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:38:34.648826 - Finished fold 5 of 5. AUROC 0.855.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:38:34.902751 - Finished fold 1 of 5. AUROC 0.798.\n",
      "2021-04-13 14:38:35.124755 - Finished fold 2 of 5. AUROC 0.834.\n",
      "2021-04-13 14:38:35.310832 - Finished fold 3 of 5. AUROC 0.845.\n",
      "2021-04-13 14:38:35.526506 - Finished fold 4 of 5. AUROC 0.850.\n",
      "2021-04-13 14:38:35.755531 - Finished fold 5 of 5. AUROC 0.833.\n",
      "\n",
      "==================== ================= ==========\n",
      "========== BEGINNING ding2016mortality ==========\n",
      "==================== ================= ==========\n",
      "Reducing sample size from 52050 to 4000 (7.68%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:38:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:38:52.914772 - Finished fold 1 of 5. AUROC 0.824.\n",
      "[14:38:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:38:55.700440 - Finished fold 2 of 5. AUROC 0.826.\n",
      "[14:38:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:38:58.732222 - Finished fold 3 of 5. AUROC 0.861.\n",
      "[14:38:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:39:01.527714 - Finished fold 4 of 5. AUROC 0.853.\n",
      "[14:39:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:39:04.320831 - Finished fold 5 of 5. AUROC 0.855.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:39:04.564361 - Finished fold 1 of 5. AUROC 0.798.\n",
      "2021-04-13 14:39:04.777711 - Finished fold 2 of 5. AUROC 0.834.\n",
      "2021-04-13 14:39:04.992544 - Finished fold 3 of 5. AUROC 0.845.\n",
      "2021-04-13 14:39:05.209692 - Finished fold 4 of 5. AUROC 0.850.\n",
      "2021-04-13 14:39:05.395220 - Finished fold 5 of 5. AUROC 0.833.\n",
      "\n",
      "==================== ======================= ==========\n",
      "========== BEGINNING ghassemi2014unfolding_a ==========\n",
      "==================== ======================= ==========\n",
      "Reducing sample size from 52050 to 23442 (45.04%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:39:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 14:39:27.763875 - Finished fold 1 of 5. AUROC 0.874.\n",
      "[14:39:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:39:38.547446 - Finished fold 2 of 5. AUROC 0.871.\n",
      "[14:39:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:39:50.325168 - Finished fold 3 of 5. AUROC 0.883.\n",
      "[14:39:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:40:02.211890 - Finished fold 4 of 5. AUROC 0.888.\n",
      "[14:40:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:40:14.159293 - Finished fold 5 of 5. AUROC 0.892.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:40:15.000911 - Finished fold 1 of 5. AUROC 0.859.\n",
      "2021-04-13 14:40:15.868141 - Finished fold 2 of 5. AUROC 0.865.\n",
      "2021-04-13 14:40:16.738417 - Finished fold 3 of 5. AUROC 0.862.\n",
      "2021-04-13 14:40:17.636319 - Finished fold 4 of 5. AUROC 0.875.\n",
      "2021-04-13 14:40:18.553728 - Finished fold 5 of 5. AUROC 0.877.\n",
      "\n",
      "==================== ======================= ==========\n",
      "========== BEGINNING ghassemi2014unfolding_b ==========\n",
      "==================== ======================= ==========\n",
      "Reducing sample size from 52050 to 28169 (54.12%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:40:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:40:41.487518 - Finished fold 1 of 5. AUROC 0.873.\n",
      "[14:40:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:40:55.673674 - Finished fold 2 of 5. AUROC 0.874.\n",
      "[14:40:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:41:09.956697 - Finished fold 3 of 5. AUROC 0.882.\n",
      "[14:41:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:41:23.876297 - Finished fold 4 of 5. AUROC 0.889.\n",
      "[14:41:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:41:36.784953 - Finished fold 5 of 5. AUROC 0.894.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:41:37.867030 - Finished fold 1 of 5. AUROC 0.850.\n",
      "2021-04-13 14:41:38.925736 - Finished fold 2 of 5. AUROC 0.857.\n",
      "2021-04-13 14:41:39.941205 - Finished fold 3 of 5. AUROC 0.856.\n",
      "2021-04-13 14:41:41.005820 - Finished fold 4 of 5. AUROC 0.872.\n",
      "2021-04-13 14:41:42.058710 - Finished fold 5 of 5. AUROC 0.875.\n",
      "\n",
      "==================== ======================= ==========\n",
      "========== BEGINNING ghassemi2014unfolding_c ==========\n",
      "==================== ======================= ==========\n",
      "Reducing sample size from 52050 to 28169 (54.12%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:41:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:42:05.107863 - Finished fold 1 of 5. AUROC 0.863.\n",
      "[14:42:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:42:19.470769 - Finished fold 2 of 5. AUROC 0.867.\n",
      "[14:42:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:42:32.916062 - Finished fold 3 of 5. AUROC 0.869.\n",
      "[14:42:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:42:46.390681 - Finished fold 4 of 5. AUROC 0.866.\n",
      "[14:42:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:43:00.598278 - Finished fold 5 of 5. AUROC 0.877.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:43:01.653332 - Finished fold 1 of 5. AUROC 0.839.\n",
      "2021-04-13 14:43:02.699738 - Finished fold 2 of 5. AUROC 0.846.\n",
      "2021-04-13 14:43:03.770661 - Finished fold 3 of 5. AUROC 0.841.\n",
      "2021-04-13 14:43:04.800543 - Finished fold 4 of 5. AUROC 0.844.\n",
      "2021-04-13 14:43:05.817396 - Finished fold 5 of 5. AUROC 0.854.\n",
      "\n",
      "==================== ======================= ==========\n",
      "========== BEGINNING ghassemi2014unfolding_d ==========\n",
      "==================== ======================= ==========\n",
      "Reducing sample size from 52050 to 28169 (54.12%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:43:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:43:28.909866 - Finished fold 1 of 5. AUROC 0.841.\n",
      "[14:43:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:43:42.778970 - Finished fold 2 of 5. AUROC 0.848.\n",
      "[14:43:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 14:43:56.709691 - Finished fold 3 of 5. AUROC 0.841.\n",
      "[14:43:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:44:11.036566 - Finished fold 4 of 5. AUROC 0.835.\n",
      "[14:44:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:44:25.019480 - Finished fold 5 of 5. AUROC 0.861.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:44:26.123332 - Finished fold 1 of 5. AUROC 0.811.\n",
      "2021-04-13 14:44:27.260537 - Finished fold 2 of 5. AUROC 0.821.\n",
      "2021-04-13 14:44:28.331306 - Finished fold 3 of 5. AUROC 0.816.\n",
      "2021-04-13 14:44:29.393740 - Finished fold 4 of 5. AUROC 0.813.\n",
      "2021-04-13 14:44:30.427896 - Finished fold 5 of 5. AUROC 0.837.\n",
      "\n",
      "==================== ========================== ==========\n",
      "========== BEGINNING ghassemi2015multivariate_a ==========\n",
      "==================== ========================== ==========\n",
      "Reducing sample size from 52050 to 21969 (42.21%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:44:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:44:52.111777 - Finished fold 1 of 5. AUROC 0.866.\n",
      "[14:44:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:45:03.419658 - Finished fold 2 of 5. AUROC 0.865.\n",
      "[14:45:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:45:14.609244 - Finished fold 3 of 5. AUROC 0.877.\n",
      "[14:45:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:45:25.795261 - Finished fold 4 of 5. AUROC 0.881.\n",
      "[14:45:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:45:37.266604 - Finished fold 5 of 5. AUROC 0.888.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:45:38.074501 - Finished fold 1 of 5. AUROC 0.853.\n",
      "2021-04-13 14:45:38.902621 - Finished fold 2 of 5. AUROC 0.858.\n",
      "2021-04-13 14:45:39.771539 - Finished fold 3 of 5. AUROC 0.855.\n",
      "2021-04-13 14:45:40.633864 - Finished fold 4 of 5. AUROC 0.869.\n",
      "2021-04-13 14:45:41.498664 - Finished fold 5 of 5. AUROC 0.874.\n",
      "\n",
      "==================== ========================== ==========\n",
      "========== BEGINNING ghassemi2015multivariate_b ==========\n",
      "==================== ========================== ==========\n",
      "Reducing sample size from 52050 to 21969 (42.21%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:45:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:46:03.905777 - Finished fold 1 of 5. AUROC 0.842.\n",
      "[14:46:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:46:14.050232 - Finished fold 2 of 5. AUROC 0.838.\n",
      "[14:46:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:46:23.270043 - Finished fold 3 of 5. AUROC 0.835.\n",
      "[14:46:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:46:32.393412 - Finished fold 4 of 5. AUROC 0.830.\n",
      "[14:46:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:46:41.966522 - Finished fold 5 of 5. AUROC 0.846.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:46:42.476176 - Finished fold 1 of 5. AUROC 0.822.\n",
      "2021-04-13 14:46:42.876488 - Finished fold 2 of 5. AUROC 0.816.\n",
      "2021-04-13 14:46:43.237986 - Finished fold 3 of 5. AUROC 0.817.\n",
      "2021-04-13 14:46:43.643741 - Finished fold 4 of 5. AUROC 0.812.\n",
      "2021-04-13 14:46:44.027999 - Finished fold 5 of 5. AUROC 0.829.\n",
      "\n",
      "==================== ==================== ==========\n",
      "========== BEGINNING grnarova2016neural_a ==========\n",
      "==================== ==================== ==========\n",
      "Reducing sample size from 52050 to 29572 (56.81%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:46:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:47:06.366894 - Finished fold 1 of 5. AUROC 0.980.\n",
      "[14:47:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:47:21.136196 - Finished fold 2 of 5. AUROC 0.984.\n",
      "[14:47:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:47:36.432046 - Finished fold 3 of 5. AUROC 0.983.\n",
      "[14:47:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:47:51.269137 - Finished fold 4 of 5. AUROC 0.984.\n",
      "[14:47:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 14:48:05.773377 - Finished fold 5 of 5. AUROC 0.983.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:48:06.339811 - Finished fold 1 of 5. AUROC 0.975.\n",
      "2021-04-13 14:48:06.853697 - Finished fold 2 of 5. AUROC 0.979.\n",
      "2021-04-13 14:48:07.357760 - Finished fold 3 of 5. AUROC 0.981.\n",
      "2021-04-13 14:48:07.932989 - Finished fold 4 of 5. AUROC 0.978.\n",
      "2021-04-13 14:48:08.532475 - Finished fold 5 of 5. AUROC 0.978.\n",
      "\n",
      "==================== ==================== ==========\n",
      "========== BEGINNING grnarova2016neural_b ==========\n",
      "==================== ==================== ==========\n",
      "Reducing sample size from 52050 to 29572 (56.81%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:48:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:48:28.984283 - Finished fold 1 of 5. AUROC 0.955.\n",
      "[14:48:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:48:44.444452 - Finished fold 2 of 5. AUROC 0.960.\n",
      "[14:48:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:48:59.550305 - Finished fold 3 of 5. AUROC 0.963.\n",
      "[14:48:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:49:14.110533 - Finished fold 4 of 5. AUROC 0.960.\n",
      "[14:49:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:49:28.594849 - Finished fold 5 of 5. AUROC 0.960.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:49:29.170628 - Finished fold 1 of 5. AUROC 0.948.\n",
      "2021-04-13 14:49:29.706171 - Finished fold 2 of 5. AUROC 0.954.\n",
      "2021-04-13 14:49:30.248919 - Finished fold 3 of 5. AUROC 0.957.\n",
      "2021-04-13 14:49:30.766288 - Finished fold 4 of 5. AUROC 0.955.\n",
      "2021-04-13 14:49:31.322087 - Finished fold 5 of 5. AUROC 0.955.\n",
      "\n",
      "==================== ==================== ==========\n",
      "========== BEGINNING grnarova2016neural_c ==========\n",
      "==================== ==================== ==========\n",
      "Reducing sample size from 52050 to 29572 (56.81%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:49:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:49:55.483689 - Finished fold 1 of 5. AUROC 0.911.\n",
      "[14:49:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:50:10.454213 - Finished fold 2 of 5. AUROC 0.912.\n",
      "[14:50:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:50:25.085511 - Finished fold 3 of 5. AUROC 0.915.\n",
      "[14:50:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:50:39.670729 - Finished fold 4 of 5. AUROC 0.908.\n",
      "[14:50:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:50:54.640741 - Finished fold 5 of 5. AUROC 0.914.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:50:55.256479 - Finished fold 1 of 5. AUROC 0.896.\n",
      "2021-04-13 14:50:55.830309 - Finished fold 2 of 5. AUROC 0.902.\n",
      "2021-04-13 14:50:56.418385 - Finished fold 3 of 5. AUROC 0.909.\n",
      "2021-04-13 14:50:57.074440 - Finished fold 4 of 5. AUROC 0.895.\n",
      "2021-04-13 14:50:57.707151 - Finished fold 5 of 5. AUROC 0.907.\n",
      "\n",
      "==================== ======================== ==========\n",
      "========== BEGINNING harutyunyan2017multitask ==========\n",
      "==================== ======================== ==========\n",
      "Reducing sample size from 52050 to 45493 (87.40%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:51:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:51:28.213556 - Finished fold 1 of 5. AUROC 0.936.\n",
      "[14:51:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:51:51.292845 - Finished fold 2 of 5. AUROC 0.949.\n",
      "[14:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:52:14.142375 - Finished fold 3 of 5. AUROC 0.940.\n",
      "[14:52:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:52:37.154287 - Finished fold 4 of 5. AUROC 0.940.\n",
      "[14:52:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:53:00.050178 - Finished fold 5 of 5. AUROC 0.940.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:53:00.929581 - Finished fold 1 of 5. AUROC 0.922.\n",
      "2021-04-13 14:53:01.798466 - Finished fold 2 of 5. AUROC 0.938.\n",
      "2021-04-13 14:53:02.646893 - Finished fold 3 of 5. AUROC 0.931.\n",
      "2021-04-13 14:53:03.506560 - Finished fold 4 of 5. AUROC 0.927.\n",
      "2021-04-13 14:53:04.376452 - Finished fold 5 of 5. AUROC 0.930.\n",
      "\n",
      "==================== ========================= ==========\n",
      "========== BEGINNING hoogendoorn2016prediction ==========\n",
      "==================== ========================= ==========\n",
      "Reducing sample size from 52050 to 17545 (33.71%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:53:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 14:53:19.166306 - Finished fold 1 of 5. AUROC 0.869.\n",
      "[14:53:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:53:27.898567 - Finished fold 2 of 5. AUROC 0.870.\n",
      "[14:53:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:53:35.604524 - Finished fold 3 of 5. AUROC 0.879.\n",
      "[14:53:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:53:43.305065 - Finished fold 4 of 5. AUROC 0.884.\n",
      "[14:53:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:53:51.491496 - Finished fold 5 of 5. AUROC 0.892.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:53:51.920346 - Finished fold 1 of 5. AUROC 0.853.\n",
      "2021-04-13 14:53:52.291438 - Finished fold 2 of 5. AUROC 0.861.\n",
      "2021-04-13 14:53:52.645914 - Finished fold 3 of 5. AUROC 0.860.\n",
      "2021-04-13 14:53:53.021583 - Finished fold 4 of 5. AUROC 0.869.\n",
      "2021-04-13 14:53:53.386712 - Finished fold 5 of 5. AUROC 0.876.\n",
      "\n",
      "==================== ========== ==========\n",
      "========== BEGINNING hug2009icu ==========\n",
      "==================== ========== ==========\n",
      "Reducing sample size from 52050 to 10696 (20.55%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:53:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:54:04.656760 - Finished fold 1 of 5. AUROC 0.854.\n",
      "[14:54:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:54:11.474481 - Finished fold 2 of 5. AUROC 0.852.\n",
      "[14:54:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:54:17.987513 - Finished fold 3 of 5. AUROC 0.868.\n",
      "[14:54:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:54:24.144907 - Finished fold 4 of 5. AUROC 0.832.\n",
      "[14:54:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:54:30.531012 - Finished fold 5 of 5. AUROC 0.886.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:54:30.773039 - Finished fold 1 of 5. AUROC 0.822.\n",
      "2021-04-13 14:54:30.995173 - Finished fold 2 of 5. AUROC 0.858.\n",
      "2021-04-13 14:54:31.215236 - Finished fold 3 of 5. AUROC 0.859.\n",
      "2021-04-13 14:54:31.460728 - Finished fold 4 of 5. AUROC 0.825.\n",
      "2021-04-13 14:54:31.662463 - Finished fold 5 of 5. AUROC 0.881.\n",
      "\n",
      "==================== ================== ==========\n",
      "========== BEGINNING johnson2012patient ==========\n",
      "==================== ================== ==========\n",
      "Reducing sample size from 52050 to 4000 (7.68%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:54:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:54:41.795503 - Finished fold 1 of 5. AUROC 0.824.\n",
      "[14:54:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:54:43.968245 - Finished fold 2 of 5. AUROC 0.826.\n",
      "[14:54:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:54:46.124503 - Finished fold 3 of 5. AUROC 0.861.\n",
      "[14:54:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:54:48.258510 - Finished fold 4 of 5. AUROC 0.853.\n",
      "[14:54:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:54:50.372708 - Finished fold 5 of 5. AUROC 0.855.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:54:50.493475 - Finished fold 1 of 5. AUROC 0.798.\n",
      "2021-04-13 14:54:50.573909 - Finished fold 2 of 5. AUROC 0.834.\n",
      "2021-04-13 14:54:50.644415 - Finished fold 3 of 5. AUROC 0.845.\n",
      "2021-04-13 14:54:50.744294 - Finished fold 4 of 5. AUROC 0.850.\n",
      "2021-04-13 14:54:50.847371 - Finished fold 5 of 5. AUROC 0.833.\n",
      "\n",
      "==================== =============== ==========\n",
      "========== BEGINNING johnson2014data ==========\n",
      "==================== =============== ==========\n",
      "Reducing sample size from 52050 to 4000 (7.68%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:54:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:55:01.986732 - Finished fold 1 of 5. AUROC 0.824.\n",
      "[14:55:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:55:04.344525 - Finished fold 2 of 5. AUROC 0.826.\n",
      "[14:55:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:55:06.530017 - Finished fold 3 of 5. AUROC 0.861.\n",
      "[14:55:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 14:55:08.978330 - Finished fold 4 of 5. AUROC 0.853.\n",
      "[14:55:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:55:11.389365 - Finished fold 5 of 5. AUROC 0.855.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:55:11.499591 - Finished fold 1 of 5. AUROC 0.798.\n",
      "2021-04-13 14:55:11.598471 - Finished fold 2 of 5. AUROC 0.834.\n",
      "2021-04-13 14:55:11.688900 - Finished fold 3 of 5. AUROC 0.845.\n",
      "2021-04-13 14:55:11.789871 - Finished fold 4 of 5. AUROC 0.850.\n",
      "2021-04-13 14:55:11.876001 - Finished fold 5 of 5. AUROC 0.833.\n",
      "\n",
      "==================== =================== ==========\n",
      "========== BEGINNING joshi2012prognostic ==========\n",
      "==================== =================== ==========\n",
      "Reducing sample size from 52050 to 10696 (20.55%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:55:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:55:22.127485 - Finished fold 1 of 5. AUROC 0.882.\n",
      "[14:55:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:55:28.311407 - Finished fold 2 of 5. AUROC 0.870.\n",
      "[14:55:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:55:34.789483 - Finished fold 3 of 5. AUROC 0.887.\n",
      "[14:55:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:55:41.039938 - Finished fold 4 of 5. AUROC 0.879.\n",
      "[14:55:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:55:46.996305 - Finished fold 5 of 5. AUROC 0.920.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:55:47.250821 - Finished fold 1 of 5. AUROC 0.850.\n",
      "2021-04-13 14:55:47.432228 - Finished fold 2 of 5. AUROC 0.871.\n",
      "2021-04-13 14:55:47.651961 - Finished fold 3 of 5. AUROC 0.878.\n",
      "2021-04-13 14:55:47.853007 - Finished fold 4 of 5. AUROC 0.882.\n",
      "2021-04-13 14:55:48.083204 - Finished fold 5 of 5. AUROC 0.909.\n",
      "\n",
      "==================== ===================== ==========\n",
      "========== BEGINNING joshi2016identifiable ==========\n",
      "==================== ===================== ==========\n",
      "Reducing sample size from 52050 to 26508 (50.93%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:55:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:56:08.897387 - Finished fold 1 of 5. AUROC 0.869.\n",
      "[14:56:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:56:20.831528 - Finished fold 2 of 5. AUROC 0.881.\n",
      "[14:56:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:56:32.339141 - Finished fold 3 of 5. AUROC 0.874.\n",
      "[14:56:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:56:44.931363 - Finished fold 4 of 5. AUROC 0.872.\n",
      "[14:56:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:56:56.722776 - Finished fold 5 of 5. AUROC 0.881.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:56:57.279675 - Finished fold 1 of 5. AUROC 0.845.\n",
      "2021-04-13 14:56:57.794337 - Finished fold 2 of 5. AUROC 0.863.\n",
      "2021-04-13 14:56:58.279020 - Finished fold 3 of 5. AUROC 0.852.\n",
      "2021-04-13 14:56:58.804382 - Finished fold 4 of 5. AUROC 0.850.\n",
      "2021-04-13 14:56:59.288732 - Finished fold 5 of 5. AUROC 0.867.\n",
      "\n",
      "==================== ====================== ==========\n",
      "========== BEGINNING lee2015customization_a ==========\n",
      "==================== ====================== ==========\n",
      "Reducing sample size from 52050 to 20961 (40.27%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:57:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:57:15.842989 - Finished fold 1 of 5. AUROC 0.874.\n",
      "[14:57:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:57:24.876259 - Finished fold 2 of 5. AUROC 0.871.\n",
      "[14:57:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:57:33.331707 - Finished fold 3 of 5. AUROC 0.882.\n",
      "[14:57:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:57:41.794835 - Finished fold 4 of 5. AUROC 0.887.\n",
      "[14:57:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:57:50.767266 - Finished fold 5 of 5. AUROC 0.886.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:57:51.183299 - Finished fold 1 of 5. AUROC 0.859.\n",
      "2021-04-13 14:57:51.567491 - Finished fold 2 of 5. AUROC 0.867.\n",
      "2021-04-13 14:57:51.949246 - Finished fold 3 of 5. AUROC 0.862.\n",
      "2021-04-13 14:57:52.365487 - Finished fold 4 of 5. AUROC 0.872.\n",
      "2021-04-13 14:57:52.760070 - Finished fold 5 of 5. AUROC 0.874.\n",
      "\n",
      "==================== ====================== ==========\n",
      "========== BEGINNING lee2015customization_b ==========\n",
      "==================== ====================== ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing sample size from 52050 to 20961 (40.27%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:57:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:58:06.985737 - Finished fold 1 of 5. AUROC 0.862.\n",
      "[14:58:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:58:15.674799 - Finished fold 2 of 5. AUROC 0.858.\n",
      "[14:58:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:58:24.132838 - Finished fold 3 of 5. AUROC 0.871.\n",
      "[14:58:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:58:32.943391 - Finished fold 4 of 5. AUROC 0.864.\n",
      "[14:58:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:58:41.441998 - Finished fold 5 of 5. AUROC 0.865.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:58:41.825960 - Finished fold 1 of 5. AUROC 0.843.\n",
      "2021-04-13 14:58:42.219717 - Finished fold 2 of 5. AUROC 0.849.\n",
      "2021-04-13 14:58:42.639574 - Finished fold 3 of 5. AUROC 0.853.\n",
      "2021-04-13 14:58:43.065632 - Finished fold 4 of 5. AUROC 0.850.\n",
      "2021-04-13 14:58:43.457361 - Finished fold 5 of 5. AUROC 0.853.\n",
      "\n",
      "==================== ====================== ==========\n",
      "========== BEGINNING lee2015customization_c ==========\n",
      "==================== ====================== ==========\n",
      "Reducing sample size from 52050 to 20961 (40.27%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:58:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:58:57.828036 - Finished fold 1 of 5. AUROC 0.845.\n",
      "[14:58:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:59:06.311274 - Finished fold 2 of 5. AUROC 0.834.\n",
      "[14:59:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:59:15.658611 - Finished fold 3 of 5. AUROC 0.833.\n",
      "[14:59:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:59:24.377476 - Finished fold 4 of 5. AUROC 0.816.\n",
      "[14:59:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:59:33.144127 - Finished fold 5 of 5. AUROC 0.838.\n",
      "=============== logreg ===============\n",
      "2021-04-13 14:59:33.557802 - Finished fold 1 of 5. AUROC 0.818.\n",
      "2021-04-13 14:59:33.952159 - Finished fold 2 of 5. AUROC 0.820.\n",
      "2021-04-13 14:59:34.368254 - Finished fold 3 of 5. AUROC 0.815.\n",
      "2021-04-13 14:59:34.811403 - Finished fold 4 of 5. AUROC 0.800.\n",
      "2021-04-13 14:59:35.253302 - Finished fold 5 of 5. AUROC 0.825.\n",
      "\n",
      "==================== =================== ==========\n",
      "========== BEGINNING lee2015personalized ==========\n",
      "==================== =================== ==========\n",
      "Reducing sample size from 52050 to 23443 (45.04%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[14:59:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:59:49.984689 - Finished fold 1 of 5. AUROC 0.862.\n",
      "[14:59:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 14:59:59.545120 - Finished fold 2 of 5. AUROC 0.861.\n",
      "[14:59:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:00:09.127408 - Finished fold 3 of 5. AUROC 0.869.\n",
      "[15:00:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:00:18.383950 - Finished fold 4 of 5. AUROC 0.870.\n",
      "[15:00:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:00:27.638384 - Finished fold 5 of 5. AUROC 0.870.\n",
      "=============== logreg ===============\n",
      "2021-04-13 15:00:28.119292 - Finished fold 1 of 5. AUROC 0.843.\n",
      "2021-04-13 15:00:28.533355 - Finished fold 2 of 5. AUROC 0.848.\n",
      "2021-04-13 15:00:28.998085 - Finished fold 3 of 5. AUROC 0.848.\n",
      "2021-04-13 15:00:29.422332 - Finished fold 4 of 5. AUROC 0.855.\n",
      "2021-04-13 15:00:29.854568 - Finished fold 5 of 5. AUROC 0.856.\n",
      "\n",
      "==================== ============== ==========\n",
      "========== BEGINNING lee2017patient ==========\n",
      "==================== ============== ==========\n",
      "Reducing sample size from 52050 to 23443 (45.04%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[15:00:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:00:49.449479 - Finished fold 1 of 5. AUROC 0.862.\n",
      "[15:00:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:00:59.133907 - Finished fold 2 of 5. AUROC 0.861.\n",
      "[15:00:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 15:01:09.622558 - Finished fold 3 of 5. AUROC 0.869.\n",
      "[15:01:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:01:18.859408 - Finished fold 4 of 5. AUROC 0.870.\n",
      "[15:01:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:01:28.328054 - Finished fold 5 of 5. AUROC 0.870.\n",
      "=============== logreg ===============\n",
      "2021-04-13 15:01:28.794507 - Finished fold 1 of 5. AUROC 0.843.\n",
      "2021-04-13 15:01:29.229035 - Finished fold 2 of 5. AUROC 0.848.\n",
      "2021-04-13 15:01:29.673381 - Finished fold 3 of 5. AUROC 0.848.\n",
      "2021-04-13 15:01:30.097838 - Finished fold 4 of 5. AUROC 0.855.\n",
      "2021-04-13 15:01:30.531820 - Finished fold 5 of 5. AUROC 0.856.\n",
      "\n",
      "==================== ============== ==========\n",
      "========== BEGINNING lehman2012risk ==========\n",
      "==================== ============== ==========\n",
      "Reducing sample size from 52050 to 21738 (41.76%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[15:01:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:01:49.329288 - Finished fold 1 of 5. AUROC 0.875.\n",
      "[15:01:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:01:58.956621 - Finished fold 2 of 5. AUROC 0.882.\n",
      "[15:01:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:02:08.122186 - Finished fold 3 of 5. AUROC 0.886.\n",
      "[15:02:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:02:17.581365 - Finished fold 4 of 5. AUROC 0.889.\n",
      "[15:02:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:02:26.499138 - Finished fold 5 of 5. AUROC 0.893.\n",
      "=============== logreg ===============\n",
      "2021-04-13 15:02:26.933535 - Finished fold 1 of 5. AUROC 0.859.\n",
      "2021-04-13 15:02:27.337458 - Finished fold 2 of 5. AUROC 0.873.\n",
      "2021-04-13 15:02:27.789572 - Finished fold 3 of 5. AUROC 0.867.\n",
      "2021-04-13 15:02:28.195175 - Finished fold 4 of 5. AUROC 0.875.\n",
      "2021-04-13 15:02:28.588677 - Finished fold 5 of 5. AUROC 0.880.\n",
      "\n",
      "==================== ====================== ==========\n",
      "========== BEGINNING luo2016interpretable_a ==========\n",
      "==================== ====================== ==========\n",
      "Reducing sample size from 52050 to 27747 (53.31%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[15:02:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:02:48.436812 - Finished fold 1 of 5. AUROC 0.926.\n",
      "[15:02:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:03:01.910939 - Finished fold 2 of 5. AUROC 0.928.\n",
      "[15:03:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:03:15.171785 - Finished fold 3 of 5. AUROC 0.931.\n",
      "[15:03:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:03:28.765860 - Finished fold 4 of 5. AUROC 0.934.\n",
      "[15:03:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:03:42.090277 - Finished fold 5 of 5. AUROC 0.928.\n",
      "=============== logreg ===============\n",
      "2021-04-13 15:03:42.655745 - Finished fold 1 of 5. AUROC 0.918.\n",
      "2021-04-13 15:03:43.195551 - Finished fold 2 of 5. AUROC 0.919.\n",
      "2021-04-13 15:03:43.710163 - Finished fold 3 of 5. AUROC 0.917.\n",
      "2021-04-13 15:03:44.244527 - Finished fold 4 of 5. AUROC 0.920.\n",
      "2021-04-13 15:03:44.788377 - Finished fold 5 of 5. AUROC 0.922.\n",
      "\n",
      "==================== ====================== ==========\n",
      "========== BEGINNING luo2016interpretable_b ==========\n",
      "==================== ====================== ==========\n",
      "Reducing sample size from 52050 to 27747 (53.31%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[15:03:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:04:09.084042 - Finished fold 1 of 5. AUROC 0.893.\n",
      "[15:04:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:04:22.784118 - Finished fold 2 of 5. AUROC 0.898.\n",
      "[15:04:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:04:36.239909 - Finished fold 3 of 5. AUROC 0.887.\n",
      "[15:04:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:04:49.521599 - Finished fold 4 of 5. AUROC 0.892.\n",
      "[15:04:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:05:03.240939 - Finished fold 5 of 5. AUROC 0.889.\n",
      "=============== logreg ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 15:05:03.818562 - Finished fold 1 of 5. AUROC 0.876.\n",
      "2021-04-13 15:05:04.363163 - Finished fold 2 of 5. AUROC 0.880.\n",
      "2021-04-13 15:05:04.911172 - Finished fold 3 of 5. AUROC 0.874.\n",
      "2021-04-13 15:05:05.451170 - Finished fold 4 of 5. AUROC 0.879.\n",
      "2021-04-13 15:05:06.009181 - Finished fold 5 of 5. AUROC 0.877.\n",
      "\n",
      "==================== ================= ==========\n",
      "========== BEGINNING luo2016predicting ==========\n",
      "==================== ================= ==========\n",
      "Reducing sample size from 52050 to 8931 (17.16%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[15:05:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:05:15.013268 - Finished fold 1 of 5. AUROC 0.823.\n",
      "[15:05:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:05:19.603343 - Finished fold 2 of 5. AUROC 0.834.\n",
      "[15:05:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:05:24.205083 - Finished fold 3 of 5. AUROC 0.832.\n",
      "[15:05:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:05:29.162875 - Finished fold 4 of 5. AUROC 0.801.\n",
      "[15:05:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:05:33.907797 - Finished fold 5 of 5. AUROC 0.849.\n",
      "=============== logreg ===============\n",
      "2021-04-13 15:05:34.139437 - Finished fold 1 of 5. AUROC 0.799.\n",
      "2021-04-13 15:05:34.321283 - Finished fold 2 of 5. AUROC 0.854.\n",
      "2021-04-13 15:05:34.503144 - Finished fold 3 of 5. AUROC 0.831.\n",
      "2021-04-13 15:05:34.664800 - Finished fold 4 of 5. AUROC 0.791.\n",
      "2021-04-13 15:05:34.836600 - Finished fold 5 of 5. AUROC 0.846.\n",
      "\n",
      "==================== ======================= ==========\n",
      "========== BEGINNING pirracchio2015mortality ==========\n",
      "==================== ======================= ==========\n",
      "Reducing sample size from 52050 to 28795 (55.32%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[15:05:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:05:54.769145 - Finished fold 1 of 5. AUROC 0.901.\n",
      "[15:05:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:06:09.901263 - Finished fold 2 of 5. AUROC 0.900.\n",
      "[15:06:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:06:24.504212 - Finished fold 3 of 5. AUROC 0.909.\n",
      "[15:06:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:06:39.509438 - Finished fold 4 of 5. AUROC 0.908.\n",
      "[15:06:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:06:54.416490 - Finished fold 5 of 5. AUROC 0.915.\n",
      "=============== logreg ===============\n",
      "2021-04-13 15:06:55.042518 - Finished fold 1 of 5. AUROC 0.883.\n",
      "2021-04-13 15:06:55.605639 - Finished fold 2 of 5. AUROC 0.890.\n",
      "2021-04-13 15:06:56.192365 - Finished fold 3 of 5. AUROC 0.891.\n",
      "2021-04-13 15:06:56.737945 - Finished fold 4 of 5. AUROC 0.896.\n",
      "2021-04-13 15:06:57.332324 - Finished fold 5 of 5. AUROC 0.899.\n",
      "\n",
      "==================== ================ ==========\n",
      "========== BEGINNING ripoll2014sepsis ==========\n",
      "==================== ================ ==========\n",
      "Reducing sample size from 52050 to 2251 (4.32%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[15:07:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:07:06.010116 - Finished fold 1 of 5. AUROC 0.792.\n",
      "[15:07:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:07:08.005264 - Finished fold 2 of 5. AUROC 0.798.\n",
      "[15:07:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:07:09.946092 - Finished fold 3 of 5. AUROC 0.804.\n",
      "[15:07:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:07:11.895542 - Finished fold 4 of 5. AUROC 0.811.\n",
      "[15:07:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:07:14.051247 - Finished fold 5 of 5. AUROC 0.810.\n",
      "=============== logreg ===============\n",
      "2021-04-13 15:07:14.141779 - Finished fold 1 of 5. AUROC 0.780.\n",
      "2021-04-13 15:07:14.220263 - Finished fold 2 of 5. AUROC 0.792.\n",
      "2021-04-13 15:07:14.293515 - Finished fold 3 of 5. AUROC 0.774.\n",
      "2021-04-13 15:07:14.343827 - Finished fold 4 of 5. AUROC 0.811.\n",
      "2021-04-13 15:07:14.404154 - Finished fold 5 of 5. AUROC 0.795.\n",
      "\n",
      "==================== ============== ==========\n",
      "========== BEGINNING wojtusiak2017c ==========\n",
      "==================== ============== ==========\n",
      "Reducing sample size from 52050 to 22699 (43.61%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[15:07:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 15:07:30.423690 - Finished fold 1 of 5. AUROC 0.796.\n",
      "[15:07:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:07:40.709015 - Finished fold 2 of 5. AUROC 0.785.\n",
      "[15:07:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:07:51.012445 - Finished fold 3 of 5. AUROC 0.796.\n",
      "[15:07:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:08:01.044787 - Finished fold 4 of 5. AUROC 0.815.\n",
      "[15:08:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:08:11.951810 - Finished fold 5 of 5. AUROC 0.791.\n",
      "=============== logreg ===============\n",
      "2021-04-13 15:08:12.466709 - Finished fold 1 of 5. AUROC 0.780.\n",
      "2021-04-13 15:08:12.921103 - Finished fold 2 of 5. AUROC 0.786.\n",
      "2021-04-13 15:08:13.345421 - Finished fold 3 of 5. AUROC 0.789.\n",
      "2021-04-13 15:08:13.818061 - Finished fold 4 of 5. AUROC 0.805.\n",
      "2021-04-13 15:08:14.262605 - Finished fold 5 of 5. AUROC 0.809.\n"
     ]
    }
   ],
   "source": [
    "mdl_val_all = dict()\n",
    "results_val_all = dict()\n",
    "pred_val_all = dict()\n",
    "tar_val_all = dict()\n",
    "\n",
    "# Rough timing info:\n",
    "#     rf - 3 seconds per fold\n",
    "#    xgb - 30 seconds per fold\n",
    "# logreg - 4 seconds per fold\n",
    "#  lasso - 8 seconds per fold\n",
    "models = OrderedDict([\n",
    "          ['xgb', xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)],\n",
    "          #['lasso', LassoCV(cv=5,fit_intercept=True,normalize=True,max_iter=10000)],\n",
    "          #['rf', RandomForestClassifier()],\n",
    "          ['logreg', LogisticRegression(fit_intercept=True)]\n",
    "         ])\n",
    "    \n",
    "with open('results.txt','w') as fp:\n",
    "    fp.write('StudyName,SampleSize,Outcome')\n",
    "    for mdl in models:\n",
    "        fp.write(',{}'.format(mdl))\n",
    "    fp.write('\\n')\n",
    "    \n",
    "for current_study in exclusions:    \n",
    "    print('\\n==================== {} =========='.format('='*len(current_study)))\n",
    "    print('========== BEGINNING {} =========='.format(current_study))\n",
    "    print('==================== {} =========='.format('='*len(current_study)))\n",
    "\n",
    "    params = exclusions[current_study][0]\n",
    "    df_data = mp.get_design_matrix(df, params[0], W=params[1], W_extra=params[2])\n",
    "\n",
    "    # get a list of icustay_id who stayed at least 12 hours\n",
    "    iid_keep = exclusions[current_study][1](co)\n",
    "    print('Reducing sample size from {} to {} ({:2.2f}%).'.format(\n",
    "            df_data.shape[0], iid_keep.shape[0], iid_keep.shape[0]*100.0 / df_data.shape[0]))\n",
    "    df_data = df_data.reindex(index = iid_keep)\n",
    "    print('')\n",
    "\n",
    "    y_outcome_label = exclusions[current_study][2]\n",
    "    \n",
    "    # load the data into a numpy array\n",
    "\n",
    "    # first, the data from static vars from df_static\n",
    "    X = df_data.merge(df_static.set_index('icustay_id')[var_static], how='left', left_index=True, right_index=True)\n",
    "    # next, add in the outcome: death in hospital\n",
    "    X = X.merge(co.set_index('icustay_id')[[y_outcome_label]], left_index=True, right_index=True)\n",
    "\n",
    "    # map above K-fold indices to this dataset\n",
    "    X = X.merge(co.set_index('icustay_id')[['subject_id']], left_index=True, right_index=True)\n",
    "    # get indices which map subject_ids in sid to the X dataframe\n",
    "    idxMap = np.searchsorted(sid, X['subject_id'].values)\n",
    "    # use these indices to map the k-fold integers\n",
    "    idxK = idxK_sid[idxMap]\n",
    "    # drop the subject_id column\n",
    "    X.drop('subject_id',axis=1,inplace=True)\n",
    "\n",
    "    # convert to numpy data (assumes target, death, is the last column)\n",
    "    X = X.values\n",
    "    y = X[:,-1]\n",
    "    X = X[:,0:-1]\n",
    "    X_header = [x for x in df_data.columns.values] + var_static\n",
    "    \n",
    "    mdl_val = dict()\n",
    "    results_val = dict()\n",
    "    pred_val = dict()\n",
    "    tar_val = dict()\n",
    "\n",
    "    for mdl in models:\n",
    "        print('=============== {} ==============='.format(mdl))\n",
    "        mdl_val[mdl] = list()\n",
    "        results_val[mdl] = list() # initialize list for scores\n",
    "        pred_val[mdl] = list()\n",
    "        tar_val[mdl] = list()\n",
    "\n",
    "        if mdl == 'xgb':\n",
    "            # no pre-processing of data necessary for xgb\n",
    "            estimator = Pipeline([(mdl, models[mdl])])\n",
    "\n",
    "        else:\n",
    "            estimator = Pipeline([(\"imputer\", SimpleImputer(missing_values=np.nan,\n",
    "                                              strategy=\"mean\")),\n",
    "                          (\"scaler\", StandardScaler()),\n",
    "                          (mdl, models[mdl])]) \n",
    "\n",
    "        for k in range(K):\n",
    "            # train the model using all but the kth fold\n",
    "            curr_mdl = estimator.fit(X[idxK != k, :],y[idxK != k])\n",
    "\n",
    "            # get prediction on this dataset\n",
    "            if mdl == 'lasso':\n",
    "                curr_prob = curr_mdl.predict(X[idxK == k, :])\n",
    "            else:\n",
    "                curr_prob = curr_mdl.predict_proba(X[idxK == k, :])\n",
    "                curr_prob = curr_prob[:,1]\n",
    "\n",
    "            pred_val[mdl].append(curr_prob)\n",
    "            tar_val[mdl].append(y[idxK == k])\n",
    "\n",
    "            # calculate score (AUROC)\n",
    "            curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "\n",
    "            # add score to list of scores\n",
    "            results_val[mdl].append(curr_score)\n",
    "\n",
    "            # save the current model\n",
    "            mdl_val[mdl].append(curr_mdl)\n",
    "\n",
    "            print('{} - Finished fold {} of {}. AUROC {:0.3f}.'.format(dt.datetime.now(), k+1, K, curr_score))\n",
    "\n",
    "    # create a pointer for above dicts with new var names\n",
    "    # we will likely re-use the dicts in subsequent calls for getting model perfomances\n",
    "    mdl_val_all[current_study] = mdl_val\n",
    "    results_val_all[current_study] = results_val\n",
    "    pred_val_all[current_study] = pred_val\n",
    "    tar_val_all[current_study] = tar_val\n",
    "    \n",
    "    # print to file\n",
    "    with open('results.txt','a') as fp:\n",
    "        # print study name, sample size and frequency of outcome\n",
    "        fp.write( '{},{},{:2.2f}'.format(current_study, X.shape[0], np.mean(y)*100.0 ) )\n",
    "        \n",
    "        for i, mdl in enumerate(models):\n",
    "            fp.write(',{:0.6f}'.format( np.mean(results_val[mdl]) ))\n",
    "        \n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the results from the above dictionaries into a single dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>N_Study</th>\n",
       "      <th>N_Repro</th>\n",
       "      <th>Y_Study</th>\n",
       "      <th>Y_Repro</th>\n",
       "      <th>AUROC_Study</th>\n",
       "      <th>xgb</th>\n",
       "      <th>logreg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohort</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>caballero2015dynamically_a</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>11648</td>\n",
       "      <td>11648.0</td>\n",
       "      <td>-</td>\n",
       "      <td>13.006525</td>\n",
       "      <td>0.8657</td>\n",
       "      <td>0.906060</td>\n",
       "      <td>0.889313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caballero2015dynamically_b</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>11648</td>\n",
       "      <td>11648.0</td>\n",
       "      <td>-</td>\n",
       "      <td>13.006525</td>\n",
       "      <td>0.7985</td>\n",
       "      <td>0.921992</td>\n",
       "      <td>0.905757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caballero2015dynamically_c</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>11648</td>\n",
       "      <td>11648.0</td>\n",
       "      <td>-</td>\n",
       "      <td>13.006525</td>\n",
       "      <td>0.7385</td>\n",
       "      <td>0.931524</td>\n",
       "      <td>0.916911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calvert2016computational</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>3054</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>12.84</td>\n",
       "      <td>13.803526</td>\n",
       "      <td>0.9340</td>\n",
       "      <td>0.957939</td>\n",
       "      <td>0.927694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calvert2016using</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>9683</td>\n",
       "      <td>18396.0</td>\n",
       "      <td>10.68</td>\n",
       "      <td>14.709720</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.933606</td>\n",
       "      <td>0.913535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celi2012database_a</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>1400</td>\n",
       "      <td>4741.0</td>\n",
       "      <td>30.7</td>\n",
       "      <td>23.919004</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.881971</td>\n",
       "      <td>0.877639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celi2012database_b</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>223</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>19.158879</td>\n",
       "      <td>0.9580</td>\n",
       "      <td>0.902528</td>\n",
       "      <td>0.878100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>che2016recurrent_a</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>4000</td>\n",
       "      <td>51986.0</td>\n",
       "      <td>13.85</td>\n",
       "      <td>3.095064</td>\n",
       "      <td>0.8424</td>\n",
       "      <td>0.985854</td>\n",
       "      <td>0.966170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ding2016mortality</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>13.85</td>\n",
       "      <td>14.350000</td>\n",
       "      <td>0.8177</td>\n",
       "      <td>0.843800</td>\n",
       "      <td>0.831932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghassemi2014unfolding_a</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>19308</td>\n",
       "      <td>23442.0</td>\n",
       "      <td>10.84</td>\n",
       "      <td>12.916987</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>0.881625</td>\n",
       "      <td>0.867505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghassemi2014unfolding_b</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>19308</td>\n",
       "      <td>28169.0</td>\n",
       "      <td>10.80</td>\n",
       "      <td>12.201356</td>\n",
       "      <td>0.8410</td>\n",
       "      <td>0.882547</td>\n",
       "      <td>0.862070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghassemi2015multivariate_a</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>10202</td>\n",
       "      <td>21969.0</td>\n",
       "      <td>-</td>\n",
       "      <td>13.514498</td>\n",
       "      <td>0.8120</td>\n",
       "      <td>0.875431</td>\n",
       "      <td>0.861783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grnarova2016neural_a</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>31244</td>\n",
       "      <td>29572.0</td>\n",
       "      <td>13.82</td>\n",
       "      <td>12.494928</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.982953</td>\n",
       "      <td>0.978397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harutyunyan2017multitask</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>42276</td>\n",
       "      <td>45493.0</td>\n",
       "      <td>-</td>\n",
       "      <td>10.535687</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.940964</td>\n",
       "      <td>0.929587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoogendoorn2016prediction</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>13923</td>\n",
       "      <td>17545.0</td>\n",
       "      <td>-</td>\n",
       "      <td>14.967227</td>\n",
       "      <td>0.8410</td>\n",
       "      <td>0.878826</td>\n",
       "      <td>0.863690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>johnson2012patient</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>14.350000</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.843800</td>\n",
       "      <td>0.831932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>johnson2014data</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>14.350000</td>\n",
       "      <td>0.8457</td>\n",
       "      <td>0.843800</td>\n",
       "      <td>0.831932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joshi2012prognostic</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>10066</td>\n",
       "      <td>10696.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.141735</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.887673</td>\n",
       "      <td>0.877910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lee2015customization_a</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>17490</td>\n",
       "      <td>20961.0</td>\n",
       "      <td>17.73</td>\n",
       "      <td>12.690234</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.879938</td>\n",
       "      <td>0.866784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lehman2012risk</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>14739</td>\n",
       "      <td>21738.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.319441</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>0.884936</td>\n",
       "      <td>0.870802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pirracchio2015mortality</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>24508</td>\n",
       "      <td>28795.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>12.720958</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.906526</td>\n",
       "      <td>0.891882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ripoll2014sepsis</th>\n",
       "      <td>death_in_hospital</td>\n",
       "      <td>2002</td>\n",
       "      <td>2251.0</td>\n",
       "      <td>21.10</td>\n",
       "      <td>39.626833</td>\n",
       "      <td>0.8223</td>\n",
       "      <td>0.803118</td>\n",
       "      <td>0.790678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>che2016recurrent_b</th>\n",
       "      <td>death_48hr_post_icu_admit</td>\n",
       "      <td>19714</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>14.350000</td>\n",
       "      <td>0.8527</td>\n",
       "      <td>0.843800</td>\n",
       "      <td>0.831932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hug2009icu</th>\n",
       "      <td>death_30dy_post_icu_disch</td>\n",
       "      <td>10066</td>\n",
       "      <td>10696.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.348168</td>\n",
       "      <td>0.8790</td>\n",
       "      <td>0.858305</td>\n",
       "      <td>0.848896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>luo2016predicting</th>\n",
       "      <td>death_30dy_post_icu_disch</td>\n",
       "      <td>7863</td>\n",
       "      <td>8931.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.449446</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.827682</td>\n",
       "      <td>0.824162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joshi2016identifiable</th>\n",
       "      <td>death_30dy_post_icu_disch</td>\n",
       "      <td>17000</td>\n",
       "      <td>26508.0</td>\n",
       "      <td>-</td>\n",
       "      <td>14.950204</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>0.875376</td>\n",
       "      <td>0.855378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghassemi2014unfolding_c</th>\n",
       "      <td>death_30dy_post_hos_disch</td>\n",
       "      <td>19308</td>\n",
       "      <td>28169.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>16.919308</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0.868359</td>\n",
       "      <td>0.844785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grnarova2016neural_b</th>\n",
       "      <td>death_30dy_post_hos_disch</td>\n",
       "      <td>31244</td>\n",
       "      <td>29572.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>16.363452</td>\n",
       "      <td>0.8580</td>\n",
       "      <td>0.959726</td>\n",
       "      <td>0.953906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lee2015personalized</th>\n",
       "      <td>death_30dy_post_hos_disch</td>\n",
       "      <td>17490</td>\n",
       "      <td>23443.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>17.941390</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>0.866411</td>\n",
       "      <td>0.849855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lee2015customization_b</th>\n",
       "      <td>death_30dy_post_hos_disch</td>\n",
       "      <td>17490</td>\n",
       "      <td>20961.0</td>\n",
       "      <td>23.56</td>\n",
       "      <td>17.861743</td>\n",
       "      <td>0.7620</td>\n",
       "      <td>0.864103</td>\n",
       "      <td>0.849443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lee2017patient</th>\n",
       "      <td>death_30dy_post_hos_disch</td>\n",
       "      <td>17152</td>\n",
       "      <td>23443.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>17.941390</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>0.866411</td>\n",
       "      <td>0.849855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>luo2016interpretable_a</th>\n",
       "      <td>death_30dy_post_hos_disch</td>\n",
       "      <td>18412</td>\n",
       "      <td>27747.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>17.054096</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.929047</td>\n",
       "      <td>0.919530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wojtusiak2017c</th>\n",
       "      <td>death_30dy_post_hos_disch</td>\n",
       "      <td>21651</td>\n",
       "      <td>22699.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.736024</td>\n",
       "      <td>0.7340</td>\n",
       "      <td>0.796452</td>\n",
       "      <td>0.793692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>luo2016interpretable_b</th>\n",
       "      <td>death_6mo_post_hos_disch</td>\n",
       "      <td>18412</td>\n",
       "      <td>27747.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>25.166685</td>\n",
       "      <td>0.8420</td>\n",
       "      <td>0.891846</td>\n",
       "      <td>0.877079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghassemi2014unfolding_d</th>\n",
       "      <td>death_1yr_post_hos_disch</td>\n",
       "      <td>19308</td>\n",
       "      <td>28169.0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>29.756115</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>0.845177</td>\n",
       "      <td>0.819566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghassemi2015multivariate_b</th>\n",
       "      <td>death_1yr_post_hos_disch</td>\n",
       "      <td>10202</td>\n",
       "      <td>21969.0</td>\n",
       "      <td>-</td>\n",
       "      <td>32.354682</td>\n",
       "      <td>0.6860</td>\n",
       "      <td>0.838118</td>\n",
       "      <td>0.818967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grnarova2016neural_c</th>\n",
       "      <td>death_1yr_post_hos_disch</td>\n",
       "      <td>31244</td>\n",
       "      <td>29572.0</td>\n",
       "      <td>12.06</td>\n",
       "      <td>24.628027</td>\n",
       "      <td>0.8530</td>\n",
       "      <td>0.911981</td>\n",
       "      <td>0.901776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lee2015customization_c</th>\n",
       "      <td>death_2yr_post_hos_disch</td>\n",
       "      <td>17152</td>\n",
       "      <td>20961.0</td>\n",
       "      <td>43.82</td>\n",
       "      <td>38.070703</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>0.833310</td>\n",
       "      <td>0.815666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mdl_list = models.keys()\n",
    "\n",
    "study_data = pd.read_csv('./data/study_data.csv')\n",
    "study_data.set_index('Cohort',inplace=True)\n",
    "\n",
    "# add in reproduction stats from earlier\n",
    "study_data_merged = study_data.merge(repro_stats, how='left',\n",
    "                left_index=True, right_index=True)\n",
    "\n",
    "# add in AUROCs\n",
    "for current_study in results_val_all:\n",
    "    results_val = results_val_all[current_study]\n",
    "    for mdl in results_val:\n",
    "        study_data_merged.loc[current_study, mdl] = np.mean(results_val[mdl])\n",
    "    \n",
    "columns = ['Outcome','N_Study','N_Repro','Y_Study','Y_Repro','AUROC_Study', 'xgb', 'logreg']\n",
    "display(HTML(study_data_merged[columns].to_html()))\n",
    "\n",
    "study_data_merged.to_csv('results_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "## Baseline model 1\n",
    "\n",
    "The below code block builds a \"baseline\" model. This model has no exclusions past the base cohort exclusions. K-fold validation is done on the patient level to ensure no information leakage between training/validation sets. The outcome is in-hospital mortality, and the data window used is the first 24 hours. Labs are extracted from up to 24 hours before the ICU admission (this is defined by `W_extra=24`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 24 # window size\n",
    "W_extra = 24 # extra time backward for labs\n",
    "y_outcome_label = 'death_in_hospital'\n",
    "\n",
    "# admission+W hours\n",
    "df_tmp=co.copy().set_index('icustay_id')\n",
    "time_dict = df_tmp.copy()\n",
    "time_dict['windowtime'] = W\n",
    "time_dict = time_dict['windowtime'].to_dict()\n",
    "\n",
    "\n",
    "# Rough timing info:\n",
    "#     rf - 3 seconds per fold\n",
    "#    xgb - 30 seconds per fold\n",
    "# logreg - 4 seconds per fold\n",
    "#  lasso - 8 seconds per fold\n",
    "models = OrderedDict([\n",
    "          ['xgb', xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)],\n",
    "          #['lasso', LassoCV(cv=5,fit_intercept=True,normalize=True,max_iter=10000)],\n",
    "          #['rf', RandomForestClassifier()],\n",
    "          ['logreg', LogisticRegression(fit_intercept=True)]\n",
    "         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "========== BEGINNING baseline ==========\n",
      "========================================\n",
      "Reducing sample size from 52085 to 38687 (74.33%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[15:13:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:13:38.842053 - Finished fold 1 of 5. AUROC 0.880.\n",
      "[15:13:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:13:51.591022 - Finished fold 2 of 5. AUROC 0.889.\n",
      "[15:13:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:14:04.812585 - Finished fold 3 of 5. AUROC 0.888.\n",
      "[15:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:14:17.173868 - Finished fold 4 of 5. AUROC 0.886.\n",
      "[15:14:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:14:29.277001 - Finished fold 5 of 5. AUROC 0.897.\n",
      "=============== logreg ===============\n",
      "2021-04-13 15:14:30.042586 - Finished fold 1 of 5. AUROC 0.869.\n",
      "2021-04-13 15:14:30.793295 - Finished fold 2 of 5. AUROC 0.872.\n",
      "2021-04-13 15:14:31.520911 - Finished fold 3 of 5. AUROC 0.864.\n",
      "2021-04-13 15:14:32.268598 - Finished fold 4 of 5. AUROC 0.863.\n",
      "2021-04-13 15:14:33.015523 - Finished fold 5 of 5. AUROC 0.882.\n",
      "\n",
      "StudyName,SampleSize,xgb,logreg\n",
      "baseline,38687,0.887931,0.870068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CENSOR_FLAG=False\n",
    "current_study = 'baseline'\n",
    "\n",
    "print('')\n",
    "print('====================={}==========='.format('='*len(current_study)))\n",
    "print('========== BEGINNING {} =========='.format(current_study))\n",
    "print('====================={}==========='.format('='*len(current_study)))\n",
    "\n",
    "# optionally remove patients who were DNR in first 24hrs\n",
    "if CENSOR_FLAG:\n",
    "    exclFcn = lambda x: x.loc[x['inclusion_stay_ge_24hr']& ( (x['censortime_hours'].isnull()) | (x['censortime_hours']>=24) ) ,'icustay_id'].values\n",
    "else:\n",
    "    exclFcn = lambda x: x.loc[x['inclusion_stay_ge_24hr']& ( (x['censortime_hours'].isnull()) | (x['censortime_hours']>=24) ) ,'icustay_id'].values\n",
    "    \n",
    "df_data = mp.get_design_matrix(df, time_dict, W=W, W_extra=W_extra)\n",
    "\n",
    "iid_keep = exclFcn(co)\n",
    "\n",
    "N_NEW=df_data.reindex(index = iid_keep).shape[0]\n",
    "print('Reducing sample size from {} to {} ({:2.2f}%).'.format(\n",
    "        co.shape[0], N_NEW, N_NEW*100.0 / df_data.shape[0]))\n",
    "df_data = df_data.reindex(index = iid_keep)\n",
    "print('')\n",
    "\n",
    "# load the data into a numpy array\n",
    "\n",
    "# first, the data from static vars from df_static\n",
    "X = df_data.merge(df_static.set_index('icustay_id')[var_static], how='left', left_index=True, right_index=True)\n",
    "# next, add in the outcome: death in hospital\n",
    "X = X.merge(co.set_index('icustay_id')[[y_outcome_label]], left_index=True, right_index=True)\n",
    "\n",
    "# map above K-fold indices to this dataset\n",
    "X = X.merge(co.set_index('icustay_id')[['subject_id']], left_index=True, right_index=True)\n",
    "# get indices which map subject_ids in sid to the X dataframe\n",
    "idxMap = np.searchsorted(sid, X['subject_id'].values)\n",
    "# use these indices to map the k-fold integers\n",
    "idxK = idxK_sid[idxMap]\n",
    "# drop the subject_id column\n",
    "X.drop('subject_id',axis=1,inplace=True)\n",
    "\n",
    "# convert to numpy data (assumes target, death, is the last column)\n",
    "X = X.values\n",
    "y = X[:,-1]\n",
    "X = X[:,0:-1]\n",
    "X_header = [x for x in df_data.columns.values] + var_static\n",
    "\n",
    "mdl_val = dict()\n",
    "results_val = dict()\n",
    "pred_val = dict()\n",
    "tar_val = dict()\n",
    "\n",
    "for mdl in models:\n",
    "    print('=============== {} ==============='.format(mdl))\n",
    "    mdl_val[mdl] = list()\n",
    "    results_val[mdl] = list() # initialize list for scores\n",
    "    pred_val[mdl] = list()\n",
    "    tar_val[mdl] = list()\n",
    "\n",
    "    if mdl == 'xgb':\n",
    "        # no pre-processing of data necessary for xgb\n",
    "        estimator = Pipeline([(mdl, models[mdl])])\n",
    "\n",
    "    else:\n",
    "        estimator = Pipeline([(\"imputer\", SimpleImputer(missing_values=np.nan,\n",
    "                                          strategy=\"mean\")),\n",
    "                      (\"scaler\", StandardScaler()),\n",
    "                      (mdl, models[mdl])]) \n",
    "\n",
    "    for k in range(K):\n",
    "        # train the model using all but the kth fold\n",
    "        curr_mdl = estimator.fit(X[idxK != k, :],y[idxK != k])\n",
    "\n",
    "        # get prediction on this dataset\n",
    "        if mdl == 'lasso':\n",
    "            curr_prob = curr_mdl.predict(X[idxK == k, :])\n",
    "        else:\n",
    "            curr_prob = curr_mdl.predict_proba(X[idxK == k, :])\n",
    "            curr_prob = curr_prob[:,1]\n",
    "\n",
    "        pred_val[mdl].append(curr_prob)\n",
    "        tar_val[mdl].append(y[idxK == k])\n",
    "\n",
    "        # calculate score (AUROC)\n",
    "        curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "\n",
    "        # add score to list of scores\n",
    "        results_val[mdl].append(curr_score)\n",
    "\n",
    "        # save the current model\n",
    "        mdl_val[mdl].append(curr_mdl)\n",
    "\n",
    "        print('{} - Finished fold {} of {}. AUROC {:0.3f}.'.format(dt.datetime.now(), k+1, K, curr_score))\n",
    "        \n",
    "\n",
    "\n",
    "# print final results\n",
    "print('')\n",
    "print('StudyName,SampleSize',end='')\n",
    "for mdl in models:\n",
    "    print(',{}'.format(mdl),end='')\n",
    "print('')\n",
    "\n",
    "print( '{},{}'.format(current_study, X.shape[0] ), end='' )\n",
    "\n",
    "for i, mdl in enumerate(models):\n",
    "    print(',{:0.6f}'.format( np.mean(results_val[mdl]) ), end='')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model 2: No care withdrawal patients\n",
    "\n",
    "Patients who choose to have their care withdrawn will receive palliative measures in the ICU. These patients show markedly different physiology than those undergoing full interventions and a model which synthesizes severity should not incorporate their data. Here we remove data for patients at the time of their withdrawal of care. If this is before the end of the first 24 hours of their ICU admission, we remove the patient entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "========== BEGINNING baseline_withdrawal ==========\n",
      "===================================================\n",
      "Reducing sample size from 52085 to 38687 (74.33%).\n",
      "\n",
      "=============== xgb ===============\n",
      "[15:17:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:17:49.245338 - Finished fold 1 of 5. AUROC 0.880.\n",
      "[15:17:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:18:01.303536 - Finished fold 2 of 5. AUROC 0.889.\n",
      "[15:18:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:18:13.936205 - Finished fold 3 of 5. AUROC 0.888.\n",
      "[15:18:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:18:27.188823 - Finished fold 4 of 5. AUROC 0.886.\n",
      "[15:18:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-04-13 15:18:40.073697 - Finished fold 5 of 5. AUROC 0.897.\n",
      "=============== logreg ===============\n",
      "2021-04-13 15:18:40.901380 - Finished fold 1 of 5. AUROC 0.869.\n",
      "2021-04-13 15:18:41.740106 - Finished fold 2 of 5. AUROC 0.872.\n",
      "2021-04-13 15:18:42.520162 - Finished fold 3 of 5. AUROC 0.864.\n",
      "2021-04-13 15:18:43.362078 - Finished fold 4 of 5. AUROC 0.863.\n",
      "2021-04-13 15:18:44.199939 - Finished fold 5 of 5. AUROC 0.882.\n",
      "\n",
      "StudyName,SampleSize,xgb,logreg\n",
      "baseline_withdrawal,38687,0.887931,0.870068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CENSOR_FLAG = True\n",
    "current_study = 'baseline_withdrawal'\n",
    "\n",
    "print('====================={}==========='.format('='*len(current_study)))\n",
    "print('========== BEGINNING {} =========='.format(current_study))\n",
    "print('====================={}==========='.format('='*len(current_study)))\n",
    "\n",
    "# optionally remove patients who were DNR in first 24hrs\n",
    "if CENSOR_FLAG:\n",
    "    exclFcn = lambda x: x.loc[x['inclusion_stay_ge_24hr']& ( (x['censortime_hours'].isnull()) | (x['censortime_hours']>=24) ) ,'icustay_id'].values\n",
    "else:\n",
    "    exclFcn = lambda x: x.loc[x['inclusion_stay_ge_24hr']& ( (x['censortime_hours'].isnull()) | (x['censortime_hours']>=24) ) ,'icustay_id'].values\n",
    "    \n",
    "df_data = mp.get_design_matrix(df, time_dict, W=W, W_extra=W_extra)\n",
    "\n",
    "iid_keep = exclFcn(co)\n",
    "N_NEW=df_data.reindex(index = iid_keep).shape[0]\n",
    "\n",
    "print('Reducing sample size from {} to {} ({:2.2f}%).'.format(\n",
    "        co.shape[0], N_NEW, N_NEW*100.0 / df_data.shape[0]))\n",
    "df_data = df_data.reindex(index = iid_keep)\n",
    "print('')\n",
    "\n",
    "# load the data into a numpy array\n",
    "\n",
    "# first, the data from static vars from df_static\n",
    "X = df_data.merge(df_static.set_index('icustay_id')[var_static], how='left', left_index=True, right_index=True)\n",
    "# next, add in the outcome: death in hospital\n",
    "X = X.merge(co.set_index('icustay_id')[[y_outcome_label]], left_index=True, right_index=True)\n",
    "\n",
    "# map above K-fold indices to this dataset\n",
    "X = X.merge(co.set_index('icustay_id')[['subject_id']], left_index=True, right_index=True)\n",
    "# get indices which map subject_ids in sid to the X dataframe\n",
    "idxMap = np.searchsorted(sid, X['subject_id'].values)\n",
    "# use these indices to map the k-fold integers\n",
    "idxK = idxK_sid[idxMap]\n",
    "# drop the subject_id column\n",
    "X.drop('subject_id',axis=1,inplace=True)\n",
    "\n",
    "# convert to numpy data (assumes target, death, is the last column)\n",
    "X = X.values\n",
    "y = X[:,-1]\n",
    "X = X[:,0:-1]\n",
    "X_header = [x for x in df_data.columns.values] + var_static\n",
    "\n",
    "mdl_val = dict()\n",
    "results_val = dict()\n",
    "pred_val = dict()\n",
    "tar_val = dict()\n",
    "\n",
    "for mdl in models:\n",
    "    print('=============== {} ==============='.format(mdl))\n",
    "    mdl_val[mdl] = list()\n",
    "    results_val[mdl] = list() # initialize list for scores\n",
    "    pred_val[mdl] = list()\n",
    "    tar_val[mdl] = list()\n",
    "\n",
    "    if mdl == 'xgb':\n",
    "        # no pre-processing of data necessary for xgb\n",
    "        estimator = Pipeline([(mdl, models[mdl])])\n",
    "\n",
    "    else:\n",
    "        estimator = Pipeline([(\"imputer\", SimpleImputer(missing_values=np.nan,\n",
    "                                          strategy=\"mean\")),\n",
    "                      (\"scaler\", StandardScaler()),\n",
    "                      (mdl, models[mdl])]) \n",
    "\n",
    "    for k in range(K):\n",
    "        # train the model using all but the kth fold\n",
    "        curr_mdl = estimator.fit(X[idxK != k, :],y[idxK != k])\n",
    "\n",
    "        # get prediction on this dataset\n",
    "        if mdl == 'lasso':\n",
    "            curr_prob = curr_mdl.predict(X[idxK == k, :])\n",
    "        else:\n",
    "            curr_prob = curr_mdl.predict_proba(X[idxK == k, :])\n",
    "            curr_prob = curr_prob[:,1]\n",
    "\n",
    "        pred_val[mdl].append(curr_prob)\n",
    "        tar_val[mdl].append(y[idxK == k])\n",
    "\n",
    "        # calculate score (AUROC)\n",
    "        curr_score = metrics.roc_auc_score(y[idxK == k], curr_prob)\n",
    "\n",
    "        # add score to list of scores\n",
    "        results_val[mdl].append(curr_score)\n",
    "\n",
    "        # save the current model\n",
    "        mdl_val[mdl].append(curr_mdl)\n",
    "\n",
    "        print('{} - Finished fold {} of {}. AUROC {:0.3f}.'.format(dt.datetime.now(), k+1, K, curr_score))\n",
    "        \n",
    "\n",
    "\n",
    "# print final results\n",
    "print('')\n",
    "print('StudyName,SampleSize',end='')\n",
    "for mdl in models:\n",
    "    print(',{}'.format(mdl),end='')\n",
    "print('')\n",
    "\n",
    "print( '{},{}'.format(current_study, X.shape[0] ), end='' )\n",
    "\n",
    "for i, mdl in enumerate(models):\n",
    "    print(',{:0.6f}'.format( np.mean(results_val[mdl]) ), end='')\n",
    "\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
